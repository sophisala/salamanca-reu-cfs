{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.769787Z",
     "start_time": "2023-06-28T19:38:56.957851Z"
    },
    "executionInfo": {
     "elapsed": 5991,
     "status": "ok",
     "timestamp": 1687200022592,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "uyv0isGdT0nL"
   },
   "outputs": [],
   "source": [
    "#!pip3 install torch torchvision torchaudio\n",
    "#!pip3 install -U scikit-learn scipy matplotlib\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as nnF\n",
    "from sklearn import metrics as skl_metrics\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import glob\n",
    "import json\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline  # uncomment this line if the plots are not showin in jupyter notebook\n",
    "\n",
    "#!pip install grad-cam\n",
    "#from pytorch_grad_cam import GradCAM, EigenCAM, FullGrad\n",
    "#from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "## This allows inbuilt cudnn auto-tuner to find the best algorithm to use for your hardware\n",
    "import torch.backends.cudnn as cudnn\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.774424Z",
     "start_time": "2023-06-28T19:38:58.771648Z"
    },
    "id": "OBO2ZGhJSDg5"
   },
   "outputs": [],
   "source": [
    "# For google drive connection in order to load the dataset\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.781274Z",
     "start_time": "2023-06-28T19:38:58.776660Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1687200027651,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "eyWBZOh59UPG",
    "outputId": "faf75dd5-24ec-489a-c28b-a02a77bc9183"
   },
   "outputs": [],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDbAZpfJTTnI"
   },
   "source": [
    "# Global Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.794557Z",
     "start_time": "2023-06-28T19:38:58.786796Z"
    },
    "code_folding": [],
    "id": "C2TYm1F9SfTY"
   },
   "outputs": [],
   "source": [
    "## General parameters\n",
    "verbose = False\n",
    "check = False\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "partitionPath = '/home/nicolas/Desktop/Poster/'\n",
    "exampleBaseFolderPath = '/home/nicolas/Desktop/Poster/examples'\n",
    "\n",
    "# This is a small dataset used to test due to the faster execution time in comparison with breakhis\n",
    "# It can be downloaded from https://www.kaggle.com/datasets/thedatasith/hymenoptera\n",
    "antsAndBeesFolderPath = '/data/raw/hymenoptera'\n",
    "#antsAndBeesFolderPath = 'drive/MyDrive/Colab Notebooks/data/hymenoptera/train'\n",
    "\n",
    "#breakhisRootPath = '/data/raw/BreaKHis_v1/'\n",
    "breakhisRootPath = 'drive/MyDrive/Colab Notebooks/data/BreaKHis_v1/BreaKHis_v1/histology_slides/breast'\n",
    "\n",
    "\n",
    "#toxoFolderPath = '/data/raw/Toxoplasmosis/classification'\n",
    "#toxoFolderPath = 'drive/MyDrive/Colab Notebooks/data/ocular_disease_classification_data2'\n",
    "toxoFolderPath = 'drive/MyDrive/Colab Notebooks/data/1000images'\n",
    "\n",
    "fileName_BM     = ['_B_', '_M_']\n",
    "path_BM         = ['benign', 'malignant']\n",
    "magnifications  = ['40X', '100X', '200X', '400X']\n",
    "\n",
    "## Enumerates and dictionaries\n",
    "folds = ['fold-0', 'fold-1', 'fold-2', 'fold-3', 'fold-4']\n",
    "class_names = [ 'Bening', 'Malignant']\n",
    "\n",
    "## Execution parameters\n",
    "num_epochs = 100     # Epochs to be trained\n",
    "#lr=0.001            # Learning rate for the training\n",
    "lr=1e-3\n",
    "#momentum=0.9        # Momentum for the training\n",
    "returned='best'     # Model to be returned in the training. ['last' (default), 'best']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xEqv64xtGNxu"
   },
   "source": [
    "# **Dataloader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.849515Z",
     "start_time": "2023-06-28T19:38:58.796582Z"
    },
    "code_folding": [],
    "id": "ZJmH0_6YN4b3"
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \"\"\"Class that contains a dataset.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Array containing the data of the dataset\n",
    "    targets : numpy.ndarray\n",
    "        Array containing tha targets associated with the data\n",
    "    \"\"\"\n",
    "    def __init__(self, data:npt.NDArray, targets:npt.NDArray):\n",
    "        self.data=data\n",
    "        self.targets=targets\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data points\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx:int):\n",
    "        x = self.data[idx]\n",
    "        y = self.targets[idx]\n",
    "        return x, y\n",
    "\n",
    "class MyLazyImageDataset(Dataset):\n",
    "    \"\"\"Class that contains an image dataset.\n",
    "    It has lazy loading of the images, saving system memory at the cost of time.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Array containing the data of the dataset\n",
    "    targets : numpy.ndarray\n",
    "        Array containing tha targets associated with the data\n",
    "    transformations : torchvision.transforms\n",
    "        Transformations to be applied to the images.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, data:npt.NDArray, targets:npt.NDArray, transformations:torchvision.transforms):\n",
    "        self.data=data\n",
    "        self.targets=targets\n",
    "        self.transformations=transformations\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of data points\n",
    "        \"\"\"\n",
    "        return self.data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.transformations(Image.open(self.data[idx]))\n",
    "        y = self.targets[idx]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "class DataContainer:\n",
    "    \"\"\"Class that contains a dataset. Allows data splitting plus dataset and dataloader creation\n",
    "    Class .\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Array containing the data of the dataset\n",
    "    targets : numpy.ndarray\n",
    "        Array containing tha targets associated with the data\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    targets = []\n",
    "\n",
    "    train_index = []\n",
    "    final_val_index = []\n",
    "    test_index = []\n",
    "    kfold_indexes = []\n",
    "\n",
    "    def __init__(self,\n",
    "                 data:npt.NDArray,\n",
    "                 targets:npt.NDArray,\n",
    "                 split_test:bool=True,\n",
    "                 test_size:float=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size:float=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.split_test=split_test\n",
    "        self.test_size=test_size\n",
    "        self.split_final_val=split_final_val\n",
    "        self.final_val_size=final_val_size\n",
    "        self.split_kfold=split_kfold\n",
    "        self.k_splits = k_splits\n",
    "        self.random_state = random_state\n",
    "\n",
    "        # Generate test indexes over the dataset\n",
    "        if self.split_test:\n",
    "            test_len=round(self.data.shape[0] * self.test_size)\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=test_len, random_state=self.random_state)\n",
    "            self.train_index, self.test_index = list(sss.split(self.data, self.targets))[0]\n",
    "        else:\n",
    "            self.train_index, self.test_index = np.array(range(0, self.data.shape[0])), []\n",
    "\n",
    "        # Generate final-validation indexes over the dataset.\n",
    "        # Intersection between taining and final-validation must be empty\n",
    "        if self.split_final_val:\n",
    "            # Number of examples to be separated refered to the original data size\n",
    "            final_val_len=round(self.data.shape[0] * self.final_val_size)\n",
    "            sss = StratifiedShuffleSplit(n_splits=1, test_size=final_val_len, random_state=self.random_state)\n",
    "            # The final_val is seprated from the data minus test subset.\n",
    "            train_index, final_val_index = list(sss.split(self.data[self.train_index], self.targets[self.train_index]))[0]\n",
    "            # But the indexes obtained must be refered to the original dataset and not the training subset\n",
    "            self.final_val_index = self.train_index[final_val_index]\n",
    "            self.train_index = self.train_index[train_index]\n",
    "        else:\n",
    "            self.train_index, self.final_val_index = self.train_index, []\n",
    "\n",
    "        # Generate train-validation k-fold indexes over the training subset\n",
    "        if self.split_kfold:\n",
    "            strtfdKFold = StratifiedKFold(n_splits=self.k_splits, shuffle=True, random_state=self.random_state)\n",
    "            self.kfold_indexes = list(strtfdKFold.split(self.data[self.train_index], self.targets[self.train_index]))\n",
    "        else:\n",
    "            self.kfold_indexes = []\n",
    "\n",
    "    # This function is needed for the possible situation in which a lazy kind of dataset may be needed\n",
    "    # (for instance for huge image datasets that need lazy load due to memory constraints)\n",
    "    def getDataset_(self, data:npt.NDArray, targets:npt.NDArray):\n",
    "        return MyDataset(data, targets)\n",
    "\n",
    "\n",
    "    def save_partition (self, file_path:str):\n",
    "        \"\"\"Saves the partition of the dataset in the given file path\n",
    "        \"\"\"\n",
    "        toSave = (self.train_index, self.final_val_index, self.test_index, self.kfold_indexes)\n",
    "        with open(file_path, 'wb') as file:\n",
    "            pd.to_pickle(toSave, file)\n",
    "            print(f'Object successfully saved to \"{file_path}\"')\n",
    "\n",
    "    def load_partition (self, file_path:str):\n",
    "        \"\"\"Loads the partition of the dataset from the given file path\n",
    "        \"\"\"\n",
    "        self.train_index, self.final_val_index, self.test_index, self.kfold_indexes = pd.read_pickle(file_path)\n",
    "\n",
    "\n",
    "    ############### Checks ###############\n",
    "\n",
    "    def check_intersection (self, verbose:bool=False):\n",
    "        \"\"\"Method that returns if there is any element of one subset (train, final_val, test) in the others.\n",
    "        If verbose is True, prints tuple (test_in_train, val_in_train, val_in_test)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            True if the intersections are 0, False otherwise\n",
    "        \"\"\"\n",
    "        test_in_train = sum(1 if x in self.train_index else 0 for x in self.test_index)\n",
    "        val_in_train = sum(1 if x in self.final_val_index else 0 for x in self.test_index)\n",
    "        val_in_test = sum(1 if x in self.train_index else 0 for x in self.final_val_index)\n",
    "        if verbose: print (test_in_train, val_in_train, val_in_test)\n",
    "        return test_in_train + val_in_train + val_in_test == 0\n",
    "\n",
    "    def check_folds (self, verbose:bool=False):\n",
    "        \"\"\"Method that returns if the folds were correctly formed: right size AND validation not intersecting AND sum(validation) == training\n",
    "        If verbose is True, prints tuple (size_ok, val_intersection_ok, all_val_eq_training_ok)\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            True if the intersections are 0, False otherwise\n",
    "        \"\"\"\n",
    "        if self.kfold_indexes is None or len(self.kfold_indexes) == 0:\n",
    "            raise FileNotFoundError('The controller was created without kfold splitting')\n",
    "        size_ok = True\n",
    "        val_acum = []\n",
    "        val_intersection = 0\n",
    "        for (train, val) in self.kfold_indexes:\n",
    "            if train.shape[0] + val.shape[0] != self.train_index.shape[0]:\n",
    "                size_ok = False\n",
    "            for v in val:\n",
    "                if v in val_acum:\n",
    "                    val_intersection += 1\n",
    "                else:\n",
    "                    val_acum.append(v)\n",
    "        val_intersection_ok = val_intersection==0\n",
    "        val_acum_ok = len(val_acum)==self.train_index.shape[0]\n",
    "        if verbose: print (size_ok, val_intersection_ok, val_acum_ok)\n",
    "        return size_ok and val_intersection_ok and val_acum_ok\n",
    "\n",
    "    ############### Data ###############\n",
    "\n",
    "    def get_data(self):\n",
    "        return (self.data, self.targets)\n",
    "\n",
    "    def get_full_train(self):\n",
    "        return (self.data[self.train_index], self.targets[self.train_index])\n",
    "\n",
    "    def get_final_val(self):\n",
    "        if self.final_val_index is None or self.final_val_index.shape[0] == 0:\n",
    "            raise FileNotFoundError('The controller was created without final_val splitting')\n",
    "        return (self.data[self.final_val_index], self.targets[self.final_val_index])\n",
    "\n",
    "    def get_test(self):\n",
    "        if self.test_index is None or self.test_index.shape[0] == 0:\n",
    "            raise FileNotFoundError('The controller was created without test splitting')\n",
    "        return (self.data[self.test_index], self.targets[self.test_index])\n",
    "\n",
    "    ############### Indexes ###############\n",
    "\n",
    "    def get_fold_indexes (self, fold:int) -> tuple[list[int], list[int]]:\n",
    "        if self.kfold_indexes is None or len(self.kfold_indexes) == 0:\n",
    "            raise FileNotFoundError('The controller was created without kfold splitting')\n",
    "        fold_train_indexes, fold_val_indexes = self.kfold_indexes[fold]\n",
    "        train_indexes = self.train_index[fold_train_indexes]\n",
    "        val_indexes = self.train_index[fold_val_indexes]\n",
    "        return (train_indexes, val_indexes)\n",
    "\n",
    "    ############### Dataset ###############\n",
    "\n",
    "    def get_data_dataset(self) -> Dataset:\n",
    "        data, targets = self.get_data()\n",
    "        data_dataset = self.getDataset_(data, targets)\n",
    "        return data_dataset\n",
    "\n",
    "    def get_full_train_dataset(self) -> Dataset:\n",
    "        train_data, train_targets = self.get_full_train()\n",
    "        return self.getDataset_(train_data, train_targets)\n",
    "\n",
    "    def get_final_val_dataset(self) -> Dataset:\n",
    "        final_val_data, final_val_targets = self.get_final_val()\n",
    "        return self.getDataset_(final_val_data, final_val_targets)\n",
    "\n",
    "    def get_test_dataset(self) -> Dataset:\n",
    "        test_data, test_targets = self.get_test()\n",
    "        return self.getDataset_(test_data, test_targets)\n",
    "\n",
    "    def get_fold_datasets (self, fold:int) -> tuple[Dataset, Dataset]:\n",
    "        train_indexes, val_indexes = self.get_fold_indexes(fold)\n",
    "        train_dataset = self.getDataset_(self.data[train_indexes], self.targets[train_indexes])\n",
    "        val_dataset = self.getDataset_(self.data[val_indexes], self.targets[val_indexes])\n",
    "        return (train_dataset, val_dataset)\n",
    "\n",
    "    ############### Dataloader ###############\n",
    "\n",
    "    def get_data_dataloader(self, batch_size:int=32, shuffle:bool=False, num_workers:int=2) -> DataLoader:\n",
    "        \"\"\"Returns a dataloader with the full data.\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of the batch. Optional. Default 32\n",
    "        shuffle : bool\n",
    "            If True, the order of the examples will be random. Optional. Default False\n",
    "        num_workers: int\n",
    "            Number of process to use. Optional. Default 2\n",
    "        \"\"\"\n",
    "        data_dataset = self.get_data_dataset()\n",
    "        return DataLoader(data_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    def get_full_train_dataloader(self, batch_size:int=32, shuffle:bool=False, num_workers:int=2) -> DataLoader:\n",
    "        \"\"\"Returns a dataloader with the full training subset.\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of the batch. Optional. Default 32\n",
    "        shuffle : bool\n",
    "            If True, the order of the examples will be random. Optional. Default False\n",
    "        num_workers: int\n",
    "            Number of process to use. Optional. Default 2\n",
    "        \"\"\"\n",
    "        train_dataset = self.get_full_train_dataset()\n",
    "        return DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    def get_final_val_dataloader(self, batch_size:int=32, shuffle:bool=False, num_workers:int=2) -> DataLoader:\n",
    "        \"\"\"Returns a dataloader with the final validation subset.\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of the batch. Optional. Default 32\n",
    "        shuffle : bool\n",
    "            If True, the order of the examples will be random. Optional. Default False\n",
    "        num_workers: int\n",
    "            Number of process to use. Optional. Default 2\n",
    "        \"\"\"\n",
    "        final_val_dataset = self.get_final_val_dataset()\n",
    "        return DataLoader(final_val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    def get_test_dataloader(self, batch_size:int=32, shuffle:bool=True, num_workers:int=2) -> DataLoader:\n",
    "        \"\"\"Returns a dataloader with the test subset.\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        batch_size : int\n",
    "            Size of the batch. Optional. Default 32\n",
    "        shuffle : bool\n",
    "            If True, the order of the examples will be random. Optional. Default False\n",
    "        num_workers: int\n",
    "            Number of process to use. Optional. Default 2\n",
    "        \"\"\"\n",
    "        test_dataset = self.get_test_dataset()\n",
    "        return DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "\n",
    "    def get_fold_dataloaders(self, fold:int, batch_size:int=32, shuffle:bool=True, num_workers:int=2) -> tuple[DataLoader, DataLoader]:\n",
    "        train_dataset, val_dataset = self.get_fold_datasets(fold)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        return (train_dataloader, val_dataloader)\n",
    "\n",
    "\n",
    "class ImageFolderDataContainer(DataContainer):\n",
    "    \"\"\"Class to process the extraction of a image dataset from a folder path.\n",
    "    The labels are extracted from the image path as the index of pathLabelsList\n",
    "    Extends DataContainer.\n",
    "    Allows data splitting plus dataset and dataloader creation.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data : numpy.ndarray\n",
    "        Array containing the data of the dataset\n",
    "    targets : numpy.ndarray\n",
    "        Array containing tha targets associated with the data\n",
    "    filepaths: numpy.ndarray[str]\n",
    "        Array with the paths of the images\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "    filepaths = []\n",
    "\n",
    "    def __init__(self,\n",
    "                 folderPath:str,\n",
    "                 extension:str,\n",
    "                 pathLabelsList: list[str],\n",
    "                 lazy:bool=False,\n",
    "                 split_test:bool=True,\n",
    "                 test_size:float=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size:float=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None,\n",
    "                 transformations:bool=None):\n",
    "        self.lazy=lazy\n",
    "        self.transformations = transformations\n",
    "        if self.transformations is None:\n",
    "            self.transformations = transforms.ToTensor()\n",
    "        data, labels = self.extract_data(folderPath, extension, pathLabelsList)\n",
    "        super().__init__(data=data,\n",
    "                         targets=labels,\n",
    "                         split_test=split_test,\n",
    "                         test_size=test_size,\n",
    "                         split_final_val=split_final_val,\n",
    "                         final_val_size=final_val_size,\n",
    "                         split_kfold=split_kfold,\n",
    "                         k_splits=k_splits,\n",
    "                         random_state=random_state)\n",
    "\n",
    "\n",
    "\n",
    "    def extract_data (self, folderPath:str, extension:str, pathLabelsList: list[str]) -> tuple[npt.NDArray, npt.NDArray]:\n",
    "        \"\"\"Function that extract the data from the given path in a recursive way.\n",
    "        \"\"\"\n",
    "        # Take the paths of all images for that magnification in the given folder and subfolders and short them alphabetically\n",
    "        filepaths = glob.glob(folderPath + \"/**/*\" + extension.lower(), recursive=True)\n",
    "        filepaths.extend(glob.glob(folderPath + \"/**/*\" + extension.upper(), recursive=True))\n",
    "        filepaths = sorted(filepaths, key=lambda s: os.path.split(s)[-1])\n",
    "\n",
    "        # Read all images and extract their labels from the path\n",
    "        images = filepaths\n",
    "        if not self.lazy:\n",
    "            images = [np.asarray(self.transformations(Image.open(fpath))) for fpath in images]\n",
    "        labels=[]\n",
    "        possibleLabelsLength = len(pathLabelsList)\n",
    "        #print(len(filepaths))\n",
    "        for fpath in filepaths:\n",
    "            for i in range(0, possibleLabelsLength):\n",
    "                if pathLabelsList[i] in fpath:\n",
    "                    labels.append(i)\n",
    "                    break\n",
    "\n",
    "        # Store filepaths, and return images and labels\n",
    "        self.filepaths = np.asarray(filepaths)\n",
    "        data = np.asarray(images)\n",
    "        labels = np.asarray(labels)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "    def getDataset_(self, data:npt.NDArray, targets:npt.NDArray) -> Dataset:\n",
    "        \"\"\"Function intended for huge image datasets that need lazy load due to memory constraints, instanties a different Dataset class\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        data: : numpy.ndarray\n",
    "            Array of images or paths of images depending of if it has been created as lazy or not\n",
    "        targets : numpy.ndarray\n",
    "            Array of target values of the data\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        Dataset:\n",
    "            Implementation of the class torch.utils.data.Dataset. It will have lazy loading if the controller has been instantiated as such.\n",
    "        \"\"\"\n",
    "        if not self.lazy:\n",
    "            return MyDataset(data, targets)\n",
    "        else:\n",
    "            return MyLazyImageDataset(data, targets, self.transformations)\n",
    "\n",
    "\n",
    "    ############### Image paths ###############\n",
    "\n",
    "    def get_data_paths(self):\n",
    "        return self.filepaths\n",
    "\n",
    "    def get_full_train_paths(self):\n",
    "        return self.filepaths[self.train_index]\n",
    "\n",
    "    def get_final_val_paths(self):\n",
    "        if self.final_val_index is None or self.final_val_index.shape[0] == 0:\n",
    "            raise FileNotFoundError('The controller was created without final_val splitting')\n",
    "        return self.filepaths[self.final_val_index]\n",
    "\n",
    "    def get_test_paths(self):\n",
    "        if self.test_index is None or self.test_index.shape[0] == 0:\n",
    "            raise FileNotFoundError('The controller was created without test splitting')\n",
    "        return self.filepaths[self.test_index]\n",
    "\n",
    "    def get_fold_paths (self, fold:int):\n",
    "        train_indexes, val_indexes = self.get_fold_indexes(fold)\n",
    "        train_paths = self.filepaths[train_indexes]\n",
    "        val_paths = self.filepaths[val_indexes]\n",
    "        return (train_paths, val_paths)\n",
    "\n",
    "\n",
    "    ############### Save images ###############\n",
    "\n",
    "    def save_transformed_images (self, indexes=[0], folder_path=\"\", base_name=\"\", extension=\".png\", verbose:bool=False):\n",
    "        for index in indexes:\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            filename, _ = os.path.splitext(os.path.split(self.filepaths[index])[-1])\n",
    "            new_file_path = os.path.join(folder_path, base_name + filename + extension)\n",
    "\n",
    "            if not self.lazy:\n",
    "                img = self.data[index]\n",
    "            else:\n",
    "                img = np.asarray(self.transformations(Image.open(self.data[index])))\n",
    "\n",
    "            plt.imshow(img.transpose((1, 2, 0)))\n",
    "            if verbose:\n",
    "                print (\"saving image to to \" + new_file_path)\n",
    "            plt.savefig(new_file_path, bbox_inches='tight')\n",
    "            if verbose:\n",
    "                print (\"saved plot to \" + new_file_path)\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "class BreakHisDataContainer(ImageFolderDataContainer):\n",
    "    \"\"\"Class for loading the BreakHis dataset from a Path. Extends ImageFolderDataContainer.\n",
    "    The labels are extracted from the image path with 'benign' = 0  and 'malignant' = 1\n",
    "    \"\"\"\n",
    "    pathLabelsList = ['benign', 'malignant']\n",
    "    extension = \".png\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 folderPath:str,\n",
    "                 lazy:bool=False,\n",
    "                 magnification:str=\"400X\",\n",
    "                 split_test:bool=True,\n",
    "                 test_size:float=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size:float=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None,\n",
    "                 transformations:torchvision.transforms=None):\n",
    "        self.magnification=magnification\n",
    "        super().__init__(folderPath=folderPath,\n",
    "                         extension=self.extension,\n",
    "                         pathLabelsList=self.pathLabelsList,\n",
    "                         lazy=lazy,\n",
    "                         split_test=split_test,\n",
    "                         test_size=test_size,\n",
    "                         split_final_val=split_final_val,\n",
    "                         final_val_size=final_val_size,\n",
    "                         split_kfold=split_kfold,\n",
    "                         k_splits=k_splits,\n",
    "                         random_state=random_state,\n",
    "                         transformations=transformations)\n",
    "\n",
    "    def extract_data (self, folderPath:str, extension:str, pathLabelsList: list[str]) -> tuple[npt.NDArray, npt.NDArray]:\n",
    "        # Take the paths of all images for that magnification in the given folder and subfolders and short them alphabetically\n",
    "        filepaths = glob.glob(folderPath + \"/**/*\" + extension.lower(), recursive=True)\n",
    "        filepaths.extend(glob.glob(folderPath + \"/**/*\" + extension.upper(), recursive=True))\n",
    "        #print(filepaths)\n",
    "        if self.magnification != \"ALL\":\n",
    "            filepaths = [fpath for fpath in filepaths if self.magnification in fpath]\n",
    "        filepaths = sorted(filepaths, key=lambda s: os.path.split(s)[-1])\n",
    "\n",
    "        # Read all images and extract their labels from the path\n",
    "        images = filepaths\n",
    "        if not self.lazy:\n",
    "            images = [np.asarray(self.transformations(Image.open(fpath))) for fpath in images]\n",
    "        labels=[]\n",
    "        possibleLabelsLength = len(pathLabelsList)\n",
    "        for fpath in filepaths:\n",
    "            for i in range(0, possibleLabelsLength):\n",
    "                if pathLabelsList[i] in fpath:\n",
    "                    labels.append(i)\n",
    "                    break\n",
    "\n",
    "        # Store filepaths, and return images and labels\n",
    "        self.filepaths = np.asarray(filepaths)\n",
    "        data = np.asarray(images)\n",
    "        labels = np.asarray(labels)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "\n",
    "class BreakHisDataContainerPatientMulticlass(BreakHisDataContainer):\n",
    "    \"\"\"Class for loading the BreakHis dataset from a Path. Extends BreakHisDataContainer.\n",
    "    The labels are extracted from the extraction ID\n",
    "    \"\"\"\n",
    "    def extract_data (self, folderPath:str, extension:str, pathLabelsList: list[str]) -> tuple[npt.NDArray, npt.NDArray]:\n",
    "        # Take the paths of all images for that magnification in the given folder and subfolders and short them alphabetically\n",
    "        filepaths = glob.glob(folderPath + \"/**/*\" + extension.lower(), recursive=True)\n",
    "        filepaths.extend(glob.glob(folderPath + \"/**/*\" + extension.upper(), recursive=True))\n",
    "        if self.magnification != \"ALL\":\n",
    "            filepaths = [fpath for fpath in filepaths if self.magnification in fpath]\n",
    "        filepaths = sorted(filepaths, key=lambda s: os.path.split(s)[-1])\n",
    "\n",
    "        # Read all images and extract their labels from the path\n",
    "        images = filepaths\n",
    "        if not self.lazy:\n",
    "            images = [np.asarray(self.transformations(Image.open(fpath))) for fpath in images]\n",
    "        slide_ids = [(fpath.split(\"/\")[-3]).split(\"-\")[-1] for fpath in self.filepaths]\n",
    "        unique_ids = list(set(slide_ids))\n",
    "        labels = [unique_ids.index(id) for id in slide_ids]\n",
    "\n",
    "        # Store filepaths, and return images and labels\n",
    "        self.filepaths = np.asarray(filepaths)\n",
    "        data = np.asarray(images)\n",
    "        labels = np.asarray(labels)\n",
    "\n",
    "        return data, labels\n",
    "\n",
    "class AntsAndBeesDataContainer(ImageFolderDataContainer):\n",
    "    \"\"\"Image Folder Data Container for Hymenoptera dataset. Extends ImageFolderDataContainer.\n",
    "    The labels are extracted from the image path with 'ants' = 0  and 'bees' = 1\n",
    "    \"\"\"\n",
    "    pathLabelsList = ['ants', 'bees']\n",
    "    extension=\".jpg\"\n",
    "    def __init__(self,\n",
    "                 folderPath:str,\n",
    "                 lazy:bool=False,\n",
    "                 split_test:bool=True,\n",
    "                 test_size=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None,\n",
    "                 transformations:torchvision.transforms=None):\n",
    "\n",
    "        super().__init__(folderPath=folderPath,\n",
    "                         extension=self.extension,\n",
    "                         pathLabelsList=self.pathLabelsList,\n",
    "                         lazy=lazy,\n",
    "                         split_test=split_test,\n",
    "                         test_size=test_size,\n",
    "                         split_final_val=split_final_val,\n",
    "                         final_val_size=final_val_size,\n",
    "                         split_kfold=split_kfold,\n",
    "                         k_splits=k_splits,\n",
    "                         random_state=random_state,\n",
    "                         transformations=transformations)\n",
    "\n",
    "\n",
    "class ToxoDataContainer(ImageFolderDataContainer):\n",
    "    pathLabelsList = ['unhealthy', 'healthy']\n",
    "    extension=\".jpg\"\n",
    "    def __init__(self,\n",
    "                 folderPath:str,\n",
    "                 lazy:bool=False,\n",
    "                 split_test:bool=True,\n",
    "                 test_size=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None,\n",
    "                 transformations:torchvision.transforms=None):\n",
    "\n",
    "        super().__init__(folderPath=folderPath,\n",
    "                         extension=self.extension,\n",
    "                         pathLabelsList=self.pathLabelsList,\n",
    "                         lazy=lazy,\n",
    "                         split_test=split_test,\n",
    "                         test_size=test_size,\n",
    "                         split_final_val=split_final_val,\n",
    "                         final_val_size=final_val_size,\n",
    "                         split_kfold=split_kfold,\n",
    "                         k_splits=k_splits,\n",
    "                         random_state=random_state,\n",
    "                         transformations=transformations)\n",
    "\n",
    "\n",
    "\n",
    "class ToxoFeaturesDataContainer(DataContainer):\n",
    "\n",
    "    def __init__(self,\n",
    "                 csvFilePath:str,\n",
    "                 extension:str,\n",
    "                 pathLabelsList: list[str],\n",
    "                 lazy:bool=False,\n",
    "                 split_test:bool=True,\n",
    "                 test_size:float=0.1,\n",
    "                 split_final_val:bool=True,\n",
    "                 final_val_size:float=0.1,\n",
    "                 split_kfold:bool=True,\n",
    "                 k_splits:int=5,\n",
    "                 random_state:int=None,\n",
    "                 transformations:bool=None):\n",
    "        self.lazy=lazy\n",
    "        self.transformations = transformations\n",
    "        if self.transformations is None:\n",
    "            self.transformations = transforms.ToTensor()\n",
    "        data, labels = self.extract_data(csvFilePath, extension, pathLabelsList)\n",
    "        super().__init__(data=data,\n",
    "                         targets=labels,\n",
    "                         split_test=split_test,\n",
    "                         test_size=test_size,\n",
    "                         split_final_val=split_final_val,\n",
    "                         final_val_size=final_val_size,\n",
    "                         split_kfold=split_kfold,\n",
    "                         k_splits=k_splits,\n",
    "                         random_state=random_state)\n",
    "\n",
    "    def extract_data (self, csvFilePath:str, extension:str, pathLabelsList: list[str]) -> tuple[npt.NDArray, npt.NDArray]:\n",
    "        \"\"\"Function that extract the data from the given cvs.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        return data, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bUgPuvGp-_WI"
   },
   "source": [
    "# **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.886200Z",
     "start_time": "2023-06-28T19:38:58.851422Z"
    },
    "code_folding": [
     27,
     70,
     99,
     120,
     139,
     144,
     155,
     191,
     219,
     270,
     294,
     308,
     427,
     510
    ],
    "id": "vs1T5DH8SxyR"
   },
   "outputs": [],
   "source": [
    "class TrainingController:\n",
    "    \"\"\"Class used to manage the training of a model plus some utilities.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    criterion : torch.nn.Module\n",
    "        Loss function to be executed during the training backward pass\n",
    "\n",
    "    max_epochs : int\n",
    "        Maximum number of epoch to train\n",
    "\n",
    "    returned : str\n",
    "        Defines if the returned model and metrics are the ones for the 'last' or 'best' epoch\n",
    "\n",
    "    metric : str\n",
    "        Defines wich of the computed metrics is going to be used to compare epoch results\n",
    "\n",
    "    plot_evolution : bool\n",
    "        Flag for showing or not a plot with the epoch evolution at the end of the training\n",
    "\n",
    "    reevaluate_training : bool\n",
    "        Flag for re-evaluation to obtain the metrics over all the training set in each epoch, or using those result obtained during training (default True)\n",
    "\n",
    "    verbose : bool\n",
    "        Level of detail printed during training (default False)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 criterion:nn.Module,\n",
    "                 max_epochs:int=25,\n",
    "                 returned:str='best',\n",
    "                 metric:str='f1',\n",
    "                 plot_evolution:bool=True,\n",
    "                 reevaluate_training:bool=True,\n",
    "                 verbose:bool=False):\n",
    "        \"\"\"Constructor\n",
    "\n",
    "        Initializes the instance of the training controller\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        criterion : torch.nn.Module\n",
    "            Loss function to be executed duering training to to the backward pass\n",
    "\n",
    "        max_epochs : int, default = 25\n",
    "            Maximum number of epoch to train\n",
    "\n",
    "        returned : str, default = 'best'\n",
    "            Defines if the returned model and metrics are the ones for the 'last' or 'best' epoch\n",
    "\n",
    "        metric : str, default = 'f1'\n",
    "            Defines wich of the computed metrics is going to be used to compare epoch results\n",
    "\n",
    "        plot_evolution : bool, default = True\n",
    "            Flag for showing or not a plot with the epoch evolution at the end of the training\n",
    "\n",
    "        reevaluate_training : bool, default = True\n",
    "            Flag for re-evaluation to obtain the metrics over all the training set in each epoch, or using those result obtained during training (default True)\n",
    "\n",
    "        verbose : bool, default = False\n",
    "            Level of detail printed during training (default False)\n",
    "        \"\"\"\n",
    "        self.max_epochs=max_epochs\n",
    "        self.returned=returned\n",
    "        self.criterion=criterion\n",
    "        self.metric=metric\n",
    "        self.plot_evolution=plot_evolution\n",
    "        self.reevaluate_training = reevaluate_training\n",
    "        self.verbose=verbose\n",
    "\n",
    "    def calculate_loss (self, predictions:torch.Tensor, trueValues:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Loss function.\n",
    "\n",
    "        Returns the loss value for the given sets of predictions and true values\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        predictions : torch.Tensor\n",
    "            Predictions made for the model\n",
    "\n",
    "        trueValues : torch.Tensor\n",
    "            True values that are the target of the predictions\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        torch.Tensor\n",
    "            The loss value for the given inputs\n",
    "\n",
    "        Raises\n",
    "        ----------\n",
    "        NotImplementedError:\n",
    "            The controller instantiated has not given an implementation to this method\n",
    "\n",
    "        Notes\n",
    "        ----------\n",
    "        Typically, the implementations will have a form like: return self.criterion(predictions, trueValues)\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"calculate_loss: A subclass must implement it\")\n",
    "\n",
    "    def extract_prefiction(self, outputs:torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Extracts the predictions from the model outputs.\n",
    "        For instance apply sigmoid in normal binary and softmax in normal multiclass classification\n",
    "\n",
    "        Args\n",
    "        ----------\n",
    "        outputs : torch.Tensor\n",
    "            Output of the model\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        torch.Tensor\n",
    "            Prediction extracted from the model outputs\n",
    "\n",
    "        Raises\n",
    "        ----------\n",
    "            NotImplementedError:\n",
    "                The controller instantiated has not given an implementation to this method\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"extract_prefiction: A subclass must implement it\")\n",
    "\n",
    "    def get_metrics (self, loss, y_true, y_pred):\n",
    "        \"\"\"Returns a collection of metrics for the labels and prediction given\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            {'loss': loss, 'acc': acc, 'f1': f1, 'cm': [tn, fp, fn, tp], 'roc_auc': roc_auc, 'pr_auc': pr_auc}\n",
    "        \"\"\"\n",
    "        tn, fp, fn, tp = skl_metrics.confusion_matrix(y_true, y_pred).ravel()\n",
    "        roc_auc = skl_metrics.roc_auc_score(y_true, y_pred)\n",
    "        acc = skl_metrics.accuracy_score(y_true, y_pred)\n",
    "        f1 = skl_metrics.f1_score(y_true, y_pred)\n",
    "        precision, recall, thresholds = skl_metrics.precision_recall_curve(y_true, y_pred)\n",
    "        pr_auc = skl_metrics.auc(recall, precision)\n",
    "\n",
    "        return {'loss': loss, 'acc': acc, 'f1': f1, 'cm': [tn, fp, fn, tp], 'roc_auc': roc_auc, 'pr_auc': pr_auc}\n",
    "\n",
    "    def print_metrics_short (self, metrics, start=''):\n",
    "        print('{} \\tLoss: {:.4f} \\tAcc: {:.4f} '.format(start, metrics['loss'], metrics['acc']))\n",
    "\n",
    "    def print_metrics_long (self, metrics, start=''):\n",
    "        print('{} \\tLoss: {:.4f} \\tAcc: {:.4f} \\tF1: {:.4f} \\tCM: {} \\tROC auc: {:.4f} \\tP/R auc: {:.4f}'.format(\n",
    "            start, metrics['loss'], metrics['acc'], metrics['f1'], metrics['cm'], metrics['roc_auc'],\n",
    "            metrics['pr_auc']))\n",
    "\n",
    "    def get_metrics_long_csv (self, metrics, parameters, separator=\",\"):\n",
    "        line = \"\"\n",
    "        for parameter in parameters:\n",
    "            line += parameter + separator\n",
    "        line += (str(metrics['loss']) + separator + str(metrics['acc']) +       separator + str(metrics['f1']) +\n",
    "                                        separator + str(metrics['cm'][0]) +     separator + str(metrics['cm'][1]) +\n",
    "                                        separator + str(metrics['cm'][2]) +     separator + str(metrics['cm'][3]) +\n",
    "                                        separator + str(metrics['roc_auc']) +   separator + str(metrics['pr_auc']))\n",
    "\n",
    "        return line\n",
    "\n",
    "    def get_evaluation_metrics (self, model, dataloader):\n",
    "        \"\"\"Function that returns a dictionary with diferent metrics obtained from evaluating the given model with the given dataset.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            tuple (train_metrics, val_metrics), being each one {'loss': loss, 'acc': acc, 'f1': f1, 'cm': [tn, fp, fn, tp], 'roc_auc': roc_auc, 'pr_auc': pr_auc}\n",
    "        \"\"\"\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "\n",
    "        running_loss = 0\n",
    "        y_pred = []\n",
    "        y_true = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # iterate over test data\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Modle prediction\n",
    "                outputs = model(inputs) # Feed Network\n",
    "                loss = self.calculate_loss(outputs, labels)\n",
    "                preds = self.extract_prefiction(outputs)\n",
    "\n",
    "                # Result acumulation\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                y_pred.extend(preds.cpu()) # Save Prediction\n",
    "                y_true.extend(labels.cpu()) # Save Truth\n",
    "\n",
    "        evaluation_loss = running_loss / len(y_true)\n",
    "        model.train(mode=was_training)\n",
    "\n",
    "        return self.get_metrics (evaluation_loss, y_true, y_pred)\n",
    "\n",
    "    def average_metrics (self, metrics):\n",
    "        \"\"\"Returns an average of the metrics collection given\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        tp = 0\n",
    "        acc = 0\n",
    "        roc_auc = 0\n",
    "        f1 = 0\n",
    "        pr_auc = 0\n",
    "        s = len(metrics)\n",
    "\n",
    "        for execution in metrics:\n",
    "            loss += execution['loss']\n",
    "            tn += execution['cm'][0]\n",
    "            fp += execution['cm'][1]\n",
    "            fn += execution['cm'][2]\n",
    "            tp += execution['cm'][3]\n",
    "            acc += execution['acc']\n",
    "            roc_auc += execution['roc_auc']\n",
    "            f1 += execution['f1']\n",
    "            pr_auc += execution['pr_auc']\n",
    "\n",
    "        return {'loss': loss/s, 'acc': acc/s, 'f1': f1/s, 'cm': [tn/s, fp/s, fn/s, tp/s], 'roc_auc': roc_auc/s, 'pr_auc': pr_auc/s}\n",
    "\n",
    "\n",
    "    def plot_epoch_evolution (self, epoch_evolution_list, metric_name='acc', plot_size=3, save_plot_filename=\"\"):\n",
    "        \"\"\"Plots a graphic with the loss evolution, accuracy evolution, and if metric_name != \"acc\", metric_name evolution\n",
    "        \"\"\"\n",
    "        loss_train_list=[]\n",
    "        loss_val_list=[]\n",
    "        acc_train_list=[]\n",
    "        acc_val_list=[]\n",
    "        metric_train_list=[]\n",
    "        metric_val_list=[]\n",
    "        for (train_metrics, val_metrics) in epoch_evolution_list:\n",
    "            loss_train_list.append(train_metrics['loss'])\n",
    "            loss_val_list.append(val_metrics['loss'])\n",
    "            acc_train_list.append(train_metrics['acc'])\n",
    "            acc_val_list.append(val_metrics['acc'])\n",
    "            metric_train_list.append(train_metrics[metric_name])\n",
    "            metric_val_list.append(val_metrics[metric_name])\n",
    "\n",
    "        figures= 2 if metric_name=='acc' else 3\n",
    "        fig, ax = plt.subplots(1, figures, figsize=(plot_size*figures, plot_size))\n",
    "        ax[0].set_title('loss v.s. epoch', fontsize=16)\n",
    "        ax[0].plot(loss_train_list, '-b', label='training loss')\n",
    "        ax[0].plot(loss_val_list, '-g', label='validation loss')\n",
    "        ax[0].set_xlabel('epoch', fontsize=16)\n",
    "        ax[0].legend(fontsize=16)\n",
    "        ax[0].grid(True)\n",
    "        ax[1].set_title('accuracy v.s. epoch', fontsize=16)\n",
    "        ax[1].plot(acc_train_list, '-b', label='training accuracy')\n",
    "        ax[1].plot(acc_val_list, '-g', label='validation accuracy')\n",
    "        ax[1].set_xlabel('epoch',fontsize=16)\n",
    "        ax[1].legend(fontsize=16)\n",
    "        ax[1].grid(True)\n",
    "        if figures==3:\n",
    "            ax[2].set_title(metric_name + ' v.s. epoch', fontsize=16)\n",
    "            ax[2].plot(metric_train_list, '-b', label='training ' + metric_name)\n",
    "            ax[2].plot(metric_val_list, '-g', label='validation ' + metric_name)\n",
    "            ax[2].set_xlabel('epoch', fontsize=16)\n",
    "            ax[2].legend(fontsize=16)\n",
    "            ax[2].grid(True)\n",
    "\n",
    "        if (save_plot_filename.strip() != \"\"):\n",
    "            fileName = save_plot_filename + \".pdf\"\n",
    "            if not os.path.exists(os.path.dirname(fileName)):\n",
    "                os.makedirs(os.path.dirname(fileName))\n",
    "            if self.verbose:\n",
    "                print (\"saving plot to \" + fileName)\n",
    "            plt.savefig(fileName, bbox_inches='tight')\n",
    "            if self.verbose:\n",
    "                print (\"saved plot to \" + fileName)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def check_convergence (self, epoch_tracking_list, min_epoch_to_convergence=20):\n",
    "        \"\"\"Function that checks a convergence condition over the epoch results.\n",
    "\n",
    "         Args\n",
    "        ----------\n",
    "            List of tuples (metrics_train, metrics_validation) ordered by time. Each position of the list is the results of one epoch.\n",
    "            Minimum number the epoch without improvement to consider that it has converged (recomended at least 20% of maximum epochs). Default 20.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            True if the maximum value of the metric has not been surprased in min_epoch_to_convergence epochs\n",
    "        \"\"\"\n",
    "        epoch_to_convergence = min_epoch_to_convergence\n",
    "        max_metric=0\n",
    "        for (_, epoch_val_metrics) in epoch_tracking_list:\n",
    "            if epoch_val_metrics[self.metric] > max_metric:\n",
    "                max_metric = epoch_val_metrics[self.metric]\n",
    "                epoch_to_convergence = min_epoch_to_convergence\n",
    "            else:\n",
    "                epoch_to_convergence -= 1\n",
    "            if epoch_to_convergence == 0:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def train_model(self,\n",
    "                    model:nn.Module,\n",
    "                    dataloader_train:DataLoader,\n",
    "                    dataloader_val:DataLoader,\n",
    "                    optimizer:optim.Optimizer,\n",
    "                    save_plot_filename=\"\",\n",
    "                    stop_on_convergence=True,\n",
    "                    metric:str=None,\n",
    "                    plot_evolution:bool=None):\n",
    "\n",
    "        returned_model, returned_epoch, epoch_tracking_list = self.train_model_(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_generator(model))\n",
    "        (train_metrics, val_metrics) = epoch_tracking_list[returned_epoch]\n",
    "        return (returned_model, val_metrics)\n",
    "\n",
    "    def train_model_(self,\n",
    "                    model:nn.Module,\n",
    "                    dataloader_train:DataLoader,\n",
    "                    dataloader_val:DataLoader,\n",
    "                    optimizer:optim.Optimizer,\n",
    "                    save_plot_filename=\"\",\n",
    "                    stop_on_convergence=True,\n",
    "                    metric:str=None,\n",
    "                    plot_evolution:bool=None):\n",
    "        \"\"\"Function that executes one training for the given model.\n",
    "        It stops when it has been executing for the 'max_epochs' defined while instantiating the controller, or when it has cenverged (function 'check_convergence')\n",
    "\n",
    "            Returns\n",
    "            ----------\n",
    "                tuple (returned_model, returned_epoch, epoch_tracking_list)\n",
    "\n",
    "                epoch_tracking_list is a list of tuples (train_metrics, val_metrics) for each epoch in order\n",
    "        \"\"\"\n",
    "        # If no concrete value has been given for this parameters, use the one used during instantiaton\n",
    "        plot_evolution = plot_evolution if plot_evolution is not None else self.plot_evolution\n",
    "        metric = metric if metric is not None else self.metric\n",
    "\n",
    "        # List to keep track of metrics evolution during training to plot at the end\n",
    "        epoch_tracking_list=[]\n",
    "        since = time.time()\n",
    "\n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        best_train_metrics = {metric:0.0}\n",
    "        best_val_metrics = {metric:0.0}\n",
    "        best_epoch = 0\n",
    "        best_model = copy.deepcopy(model)\n",
    "\n",
    "        for epoch in range(self.max_epochs):\n",
    "            print('Epoch {}/{}'.format(epoch, self.max_epochs - 1))\n",
    "            if self.verbose:\n",
    "                print('-' * 10)\n",
    "            epoch_since = time.time()\n",
    "\n",
    "            model.train()  # Set model to training mode\n",
    "            running_loss = 0\n",
    "            y_true = []\n",
    "            y_pred = []\n",
    "\n",
    "            # Iterate over data.\n",
    "            for i, (inputs, labels) in enumerate(dataloader_train):\n",
    "\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Transforming loop\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(True):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = self.calculate_loss(outputs, labels)\n",
    "                    preds = self.extract_prefiction(outputs)\n",
    "\n",
    "                # backward + optimize\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # Result acumulation\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                y_pred.extend(preds.cpu()) # Save Prediction\n",
    "                y_true.extend(labels.cpu()) # Save Truth\n",
    "\n",
    "            # Epoch evaluation\n",
    "            training_loss = running_loss / len(y_true)\n",
    "            training_metrics = self.get_metrics (training_loss, y_true, y_pred)\n",
    "            train_metrics = training_metrics\n",
    "            if self.reevaluate_training:\n",
    "                train_metrics = self.get_evaluation_metrics(model, dataloader_train)\n",
    "            val_metrics = self.get_evaluation_metrics(model, dataloader_val)\n",
    "            epoch_tracking_list.append((train_metrics, val_metrics))\n",
    "\n",
    "            if self.verbose:\n",
    "                epoch_time_elapsed = time.time() - epoch_since\n",
    "                self.print_metrics_short(training_metrics, 'Training')\n",
    "                if self.reevaluate_training:\n",
    "                    self.print_metrics_long(train_metrics, 'Train\\t')\n",
    "                self.print_metrics_long(val_metrics, 'Val\\t')\n",
    "                print('Time: {:.0f}m {:.0f}s'.format(epoch_time_elapsed // 60, epoch_time_elapsed % 60))\n",
    "                print('')\n",
    "\n",
    "            # deep copy the model\n",
    "            if self.returned == 'best' and val_metrics[metric] > best_val_metrics[metric]:\n",
    "                best_train_metrics = train_metrics\n",
    "                best_val_metrics = val_metrics\n",
    "                best_model = copy.deepcopy(model)\n",
    "                best_epoch = epoch\n",
    "\n",
    "            # If the model has converged, break the epoch loop\n",
    "            if stop_on_convergence and self.check_convergence(epoch_tracking_list):\n",
    "                break\n",
    "\n",
    "        if plot_evolution:\n",
    "            print('\\n\\n')\n",
    "            self.plot_epoch_evolution (epoch_tracking_list, metric, save_plot_filename=save_plot_filename)\n",
    "\n",
    "        if self.returned == 'best':\n",
    "            returned_train_metrics = best_train_metrics\n",
    "            returned_val_metrics = best_val_metrics\n",
    "            returned_model = best_model\n",
    "            returned_epoch = best_epoch\n",
    "        else:\n",
    "            returned_train_metrics = train_metrics\n",
    "            returned_val_metrics = val_metrics\n",
    "            returned_model = copy.deepcopy(model)\n",
    "            returned_epoch = epoch\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s. Epoch returned: {} ({})'.format(time_elapsed // 60, time_elapsed % 60, returned_epoch, returned))\n",
    "        (returned_train_metrics, returned_val_metrics) = epoch_tracking_list[returned_epoch]\n",
    "        self.print_metrics_long(returned_train_metrics, 'Returned train')\n",
    "        self.print_metrics_long(returned_val_metrics, 'Returned val')\n",
    "\n",
    "        return (returned_model, returned_epoch, epoch_tracking_list)\n",
    "\n",
    "    def plot_cross_fold_evolution (self, cross_fold_tracking, k_splits, metric_name='acc', plot_size=3, save_plot_filename=\"\"):\n",
    "        \"\"\"Plots a graphic with the loss evolution, accuracy evolution, and if metric_name != \"acc\", metric_name evolution\n",
    "        \"\"\"\n",
    "\n",
    "        # Creating plot grid\n",
    "        vseparation = 0.25\n",
    "        figures= 2 if metric_name=='acc' else 3\n",
    "        fig, ax = plt.subplots(2, figures, figsize=(plot_size*figures, plot_size*2 + vseparation))\n",
    "\n",
    "        # more vertical spacing between plots\n",
    "        fig.subplots_adjust(hspace=vseparation)\n",
    "\n",
    "        # Color range\n",
    "        colors = ['-b', '-r', '-g', '-o', '-y']\n",
    "        #colors = ['-b', '-r', '-g', '-g', '-g']\n",
    "        colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k', 'w']\n",
    "\n",
    "        # Adding titles and axes\n",
    "        ax[0, 0].set_title('Training loss', fontsize=16)\n",
    "        ax[0, 1].set_title('Training acc', fontsize=16)\n",
    "        ax[1, 0].set_title('Validation loss', fontsize=16)\n",
    "        ax[1, 1].set_title('Validation acc', fontsize=16)\n",
    "\n",
    "        ax[0, 0].set_xlabel('epoch', fontsize=16)\n",
    "        ax[0, 1].set_xlabel('epoch', fontsize=16)\n",
    "        ax[1, 0].set_xlabel('epoch', fontsize=16)\n",
    "        ax[1, 1].set_xlabel('epoch', fontsize=16)\n",
    "\n",
    "        if figures==3:\n",
    "            ax[0, 2].set_title('Training ' + metric_name, fontsize=16)\n",
    "            ax[1, 2].set_title('Validation ' + metric_name, fontsize=16)\n",
    "\n",
    "            ax[0, 2].set_xlabel('epoch', fontsize=16)\n",
    "            ax[1, 2].set_xlabel('epoch', fontsize=16)\n",
    "\n",
    "        # For each fold\n",
    "        for fold in range(0, k_splits):\n",
    "            loss_train_list=[]\n",
    "            loss_val_list=[]\n",
    "            acc_train_list=[]\n",
    "            acc_val_list=[]\n",
    "            metric_train_list=[]\n",
    "            metric_val_list=[]\n",
    "\n",
    "            # Extract epoch data\n",
    "            for (train_metrics, val_metrics) in cross_fold_tracking[fold]:\n",
    "                loss_train_list.append(train_metrics['loss'])\n",
    "                loss_val_list.append(val_metrics['loss'])\n",
    "                acc_train_list.append(train_metrics['acc'])\n",
    "                acc_val_list.append(val_metrics['acc'])\n",
    "                metric_train_list.append(train_metrics[metric_name])\n",
    "                metric_val_list.append(val_metrics[metric_name])\n",
    "\n",
    "            # Add data to plots\n",
    "            fold_name = \"fold-\" + str(fold)\n",
    "            ax[0, 0].plot(loss_train_list, colors[fold], label=fold_name)\n",
    "            ax[0, 1].plot(acc_train_list, colors[fold], label=fold_name)\n",
    "            ax[1, 0].plot(loss_val_list, colors[fold], label=fold_name)\n",
    "            ax[1, 1].plot(acc_val_list, colors[fold], label=fold_name)\n",
    "            if figures==3:\n",
    "                ax[0, 2].plot(metric_train_list, colors[fold], label=fold_name)\n",
    "                ax[1, 2].plot(metric_val_list, colors[fold], label=fold_name)\n",
    "\n",
    "        ax[0, 0].legend(fontsize=16)\n",
    "        ax[0, 1].legend(fontsize=16)\n",
    "        ax[1, 0].legend(fontsize=16)\n",
    "        ax[1, 1].legend(fontsize=16)\n",
    "\n",
    "        if figures==3:\n",
    "            ax[0, 2].legend(fontsize=16)\n",
    "            ax[1, 2].legend(fontsize=16)\n",
    "\n",
    "        if (save_plot_filename.strip() != \"\"):\n",
    "            fileName = save_plot_filename + \".pdf\"\n",
    "            if not os.path.exists(os.path.dirname(fileName)):\n",
    "                os.makedirs(os.path.dirname(fileName))\n",
    "            if self.verbose:\n",
    "                print (\"saving plot to \" + fileName)\n",
    "            plt.savefig(fileName, bbox_inches='tight')\n",
    "            if self.verbose:\n",
    "                print (\"saved plot to \" + fileName)\n",
    "        plt.show()\n",
    "\n",
    "    def execute_cross_fold (self,\n",
    "                            dataContainer:DataContainer,\n",
    "                            model_generator,\n",
    "                            optimizer_generator,\n",
    "                            save_plot_filename:str=\"\",\n",
    "                            stop_on_convergence=True,\n",
    "                            metric:str=None,\n",
    "                            plot_evolution:bool=None):\n",
    "        \"\"\"Function that executes a cross fold validation calling to the function \"get_fold_dataloaders(fold, batch_size)\" of the dataContainer.\n",
    "\n",
    "            Args\n",
    "        ----------\n",
    "            Needs as parameters a function \"model_generator\" that creates a new model to be trained and \"optimizer_generator(model)\" that creates an optimizer for a model to be trained with\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "            Average between folds of the validation metrics of the best/last model as configured when the controller was instantiated.\n",
    "        \"\"\"\n",
    "        # If no concrete value has been given for this parameters, use the one used during instantiaton\n",
    "        plot_evolution = plot_evolution if plot_evolution is not None else self.plot_evolution\n",
    "        metric = metric if metric is not None else self.metric\n",
    "\n",
    "        fold_results=[]\n",
    "        cross_fold_tracking = []\n",
    "\n",
    "        since = time.time()\n",
    "        for fold in range(0, dataContainer.k_splits):\n",
    "            print('\\n--------------------------------------------------------------\\n')\n",
    "            print('fold:', fold, '\\n------------')\n",
    "\n",
    "            train_dataloader, val_dataloader = dataContainer.get_fold_dataloaders(fold, batch_size=32)\n",
    "\n",
    "            model = model_generator()\n",
    "            optimizer = optimizer_generator(model)\n",
    "\n",
    "            fold_save_plot_filename = save_plot_filename\n",
    "            if (fold_save_plot_filename.strip() != \"\"):\n",
    "                fold_save_plot_filename += \"_fold-\" + str(fold)\n",
    "\n",
    "            returned_model, returned_epoch, epoch_tracking_list = self.train_model_(model, train_dataloader, val_dataloader,\n",
    "                                                                                   optimizer=optimizer, save_plot_filename=fold_save_plot_filename,\n",
    "                                                                                   stop_on_convergence=stop_on_convergence, plot_evolution=False, metric=metric)\n",
    "            fold_results.append(epoch_tracking_list[returned_epoch])\n",
    "            cross_fold_tracking.append(epoch_tracking_list)\n",
    "\n",
    "        print('\\n--------------------------------------------------------------\\n\\n')\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Full CV in {:.0f}m {:.0f}s\\n'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "        if plot_evolution:\n",
    "            print('\\n\\n')\n",
    "            self.plot_cross_fold_evolution (cross_fold_tracking=cross_fold_tracking, k_splits=dataContainer.k_splits, metric_name=metric, save_plot_filename=save_plot_filename)\n",
    "\n",
    "        val_metrics_list = []\n",
    "        print(\"\\n\\tValidation results:\")\n",
    "        for fold, (_, val_metrics) in enumerate(fold_results):\n",
    "            self.print_metrics_long(val_metrics, '\\t\\tFold-{}'.format(fold))\n",
    "            val_metrics_list.append(val_metrics)\n",
    "\n",
    "        average_val_metrics = trainingController.average_metrics (val_metrics_list)\n",
    "        self.print_metrics_long(average_val_metrics, '\\n\\n\\tAverage:')\n",
    "\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "        return average_val_metrics\n",
    "\n",
    "####### IMPLEMENTATIONS #######\n",
    "\n",
    "class BinaryClassificationTrainingController (TrainingController):\n",
    "    \"\"\"Class for training binary classification models.\n",
    "    \"\"\"\n",
    "    def calculate_loss (self, predictions:torch.Tensor, trueValues:torch.Tensor) -> torch.Tensor:\n",
    "        return self.criterion(predictions.view(-1), trueValues.to(predictions.dtype))\n",
    "\n",
    "    def extract_prefiction(self, outputs:torch.Tensor) -> torch.Tensor:\n",
    "        return (outputs.view(-1).data > 0).cpu()\n",
    "\n",
    "\n",
    "class MulticlassClassificationTrainingController (TrainingController):\n",
    "    \"\"\"Class for training multiclass classification models.\n",
    "    \"\"\"\n",
    "    def calculate_loss (self, predictions:torch.Tensor, trueValues:torch.Tensor) -> torch.Tensor:\n",
    "        return self.criterion(predictions, trueValues)\n",
    "\n",
    "    def extract_prefiction(self, outputs:torch.Tensor) -> torch.Tensor:\n",
    "        return (outputs.data.max(dim=1)[1]).cpu()\n",
    "\n",
    "    # TODO The confusion matrix and f1 doesn't work for more than 2 classes\n",
    "    def get_metrics_tenative (self, loss, y_true, y_pred):\n",
    "        \"\"\"Returns a collection of metrics for the labels and prediction given\n",
    "        \"\"\"\n",
    "        cm = skl_metrics.confusion_matrix(y_true, y_pred)\n",
    "        tn, fp, fn, tp = (0, 0, 0, 0)\n",
    "        roc_auc = skl_metrics.roc_auc_score(y_true, y_pred)\n",
    "        roc_auc = 0\n",
    "        acc = skl_metrics.accuracy_score(y_true, y_pred)\n",
    "        f1 = 0\n",
    "        #f1 = skl_metrics.f1_score(y_true, y_pred)\n",
    "        #f1 = skl_metrics.f1_score(y_true, y_pred, average=None)\n",
    "        #precision, recall, thresholds = skl_metrics.precision_recall_curve(y_true, y_pred)\n",
    "        #pr_auc = skl_metrics.auc(recall, precision)\n",
    "        pr_auc = 0\n",
    "\n",
    "        return {'loss': loss, 'acc': acc, 'f1': f1, 'cm': [tp, fp, tn, fn], 'roc_auc': roc_auc, 'pr_auc': pr_auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcCD5QYU_MrK"
   },
   "source": [
    "# Explainable AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.900536Z",
     "start_time": "2023-06-28T19:38:58.889129Z"
    },
    "id": "tOKvLDOiHXOf"
   },
   "outputs": [],
   "source": [
    "\n",
    "def normalize_color_image(I):\n",
    "    I_max = I.max(axis=(0,1), keepdims=True)\n",
    "    I_min = I.min(axis=(0,1), keepdims=True)\n",
    "    I = (I - I_min)/(I_max-I_min)\n",
    "    return I\n",
    "\n",
    "def explaination_single_models (img, label, modelList):\n",
    "\n",
    "    numImages = len(modelList)+1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('abs(dL/dx)')\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    ffig, ax = plt.subplots(1, 2, figsize=(12,10))\n",
    "    x=img.to(device)\n",
    "    ax[0].imshow(x.detach().cpu().numpy().squeeze().transpose(1,2,0))\n",
    "    ax[0].set_title('input image x, label='+str(label), fontsize=16)\n",
    "    #--------------------------------------------------\n",
    "    x=img.to(device)\n",
    "    x.requires_grad=True\n",
    "    z=model(x).view(1)\n",
    "    y=torch.tensor([label], dtype=x.dtype, device=device)\n",
    "    loss = nnF.binary_cross_entropy_with_logits(z, y)\n",
    "    loss.backward()\n",
    "    #--------------------------------------------------\n",
    "    y=y.item()\n",
    "    xx = x.detach().cpu().numpy().squeeze()\n",
    "    xx=xx.transpose(1,2,0)\n",
    "    x_grad=x.grad.data.detach().cpu().numpy().squeeze()\n",
    "    x_grad=x_grad.transpose(1,2,0)\n",
    "    x_grad=np.abs(x_grad).sum(axis=2)\n",
    "    xx = normalize_color_image(xx)\n",
    "    #--------------------------------------------------\n",
    "    ax[1].imshow(x_grad, cmap='gray', vmin=x_grad.min(), vmax=x_grad.max())\n",
    "    ax[1].set_title('abs(dL/dx)', fontsize=16)\n",
    "\n",
    "def explaination_multiple_models (img, label, modelList):\n",
    "\n",
    "    numImages = len(modelList)+1\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print('abs(dL/dx)')\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    fig, ax = plt.subplots(1, numImages, figsize=(24,20))\n",
    "    x=img.to(device)\n",
    "    ax[0].imshow(x.detach().cpu().numpy().squeeze().transpose(1,2,0))\n",
    "    ax[0].set_title('input image x, label='+str(label), fontsize=16)\n",
    "\n",
    "    i = 1\n",
    "    for (name, model) in modelList:\n",
    "        x=img.to(device)\n",
    "        x.requires_grad=True\n",
    "        z=model(x).view(-1)\n",
    "        prediction = (z.data > 0).to(torch.int64).item()\n",
    "        y=torch.tensor([label], dtype=x.dtype, device=device)\n",
    "        loss = nnF.binary_cross_entropy_with_logits(z, y)\n",
    "        loss.backward()\n",
    "        #--------------------------------------------------\n",
    "        y=y.item()\n",
    "        xx = x.detach().cpu().numpy().squeeze()\n",
    "        xx=xx.transpose(1,2,0)\n",
    "        x_grad=x.grad.data.detach().cpu().numpy().squeeze()\n",
    "        x_grad=x_grad.transpose(1,2,0)\n",
    "        x_grad=np.abs(x_grad).sum(axis=2)\n",
    "        xx = normalize_color_image(xx)\n",
    "        ax[i].imshow(x_grad, cmap='gray', vmin=x_grad.min(), vmax=x_grad.max())\n",
    "        ax[i].set_title(name + ', pred='+str(prediction), fontsize=16)\n",
    "        #--------------------------------------------------\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.910221Z",
     "start_time": "2023-06-28T19:38:58.904052Z"
    },
    "id": "hrAS0LuARc0X"
   },
   "outputs": [],
   "source": [
    "class ClassifierOutputTarget:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def __call__(self, model_output):\n",
    "        return model_output.sum()\n",
    "\n",
    "def cam_multiple_models (img, label, modelList, cam_name, label_list_str=[\"0\", \"1\"]):\n",
    "\n",
    "    numImages = len(modelList)+1\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    #--------------------------------------------------\n",
    "    fig, ax = plt.subplots(1, numImages, figsize=(24,20))\n",
    "    img=np.asarray(img)\n",
    "    img=img.squeeze()\n",
    "    img=img.transpose(1,2,0)\n",
    "    img=img.astype(\"float32\")\n",
    "    img=img/img.max()\n",
    "    ax[0].imshow(img)\n",
    "    ax[0].set_title('input image x, label='+ label_list_str[label.item()], fontsize=16)\n",
    "\n",
    "    i = 1\n",
    "    for (name, model) in modelList:\n",
    "\n",
    "        #initial_status = model.layer4.requires_grad\n",
    "\n",
    "        #unfreeze target layers\n",
    "        for param in model.layer4.parameters():\n",
    "          param.requires_grad = True\n",
    "\n",
    "        model.to(device)\n",
    "        target_layers = [model.layer4[-1]]\n",
    "        image_input=torch.tensor(img).permute(2,0,1).view(1,3,224,224)\n",
    "\n",
    "        prediction = 1 if ((model(image_input)).cpu().view(-1).data > 0).item() else 0\n",
    "\n",
    "        #--------------------------------------------------\n",
    "\n",
    "        # Develop the CAM object\n",
    "        if(cam_name == 'gradcam'):\n",
    "          cam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)\n",
    "        if(cam_name == 'eigencam'):\n",
    "          cam = EigenCAM(model=model, target_layers=target_layers, use_cuda=False)\n",
    "        if(cam_name == 'fullgrad'):\n",
    "          cam = FullGrad(model=model, target_layers=target_layers, use_cuda=False)\n",
    "\n",
    "        targets = [ClassifierOutputTarget()]\n",
    "        grayscale_cam = cam(input_tensor=image_input, targets=targets)\n",
    "        grayscale_cam=grayscale_cam[0]\n",
    "        cam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\n",
    "        ax[i].imshow(cam_image)\n",
    "        ax[i].set_title(name + ', pred=' + label_list_str[prediction] + ', ' + cam_name, fontsize=16)\n",
    "\n",
    "        #freeze target layers to return to original model state\n",
    "        #for param in model.layer4.parameters():\n",
    "          #param.requires_grad = initial_status\n",
    "\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6FykKwKjp8b"
   },
   "source": [
    "# Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.929769Z",
     "start_time": "2023-06-28T19:38:58.911629Z"
    },
    "id": "I4NdVO4Kjn38"
   },
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "#   The data has to have the folder structure of\n",
    "#\n",
    "#       unhealthy\n",
    "#           |\n",
    "#           |--- toxo\n",
    "#           |--- retinoplasmosys\n",
    "#           |--- ....\n",
    "#           |--- ....\n",
    "#           |--- ....\n",
    "#       healthy\n",
    "#           |--- normal\n",
    "#\n",
    "# The resulting csv will have the structure: imageName, binaryLabel, MulticlassLabel, features*\n",
    "#################################################################################\n",
    "\n",
    "def get_activation(observers, observer_name):\n",
    "    def hook(model, input, output):\n",
    "        observers[observer_name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def transform_images_to_features_csv (model, observers, observer_name, dataContainer, output_file='features.csv', sublabels=False, separator=','):\n",
    "\n",
    "    # Get Input\n",
    "    data_dataloader = dataContainer.get_data_dataloader(batch_size=1,shuffle=False)\n",
    "    data_paths = dataContainer.get_data_paths()\n",
    "\n",
    "    # Write file\n",
    "    f = open(output_file, \"w\")\n",
    "    for i, (input, label) in enumerate(data_dataloader):\n",
    "\n",
    "        # Obtain full mopdel output\n",
    "        output = model(input)\n",
    "        features = (torch.flatten(observers[observer_name])).cpu().numpy()\n",
    "        imagePath = data_paths[i]\n",
    "        imageName = os.path.split(imagePath)[-1]\n",
    "        sublabel_name=''\n",
    "        if sublabels:\n",
    "            sublabel_name = os.path.split(os.path.split(imagePath)[-2])[-1]\n",
    "        label_name = dataContainer.pathLabelsList[label]\n",
    "\n",
    "        # Convert the features in a csv string\n",
    "        features_string = \"\"\n",
    "        for feature in features:\n",
    "            features_string += str(feature) + separator\n",
    "        # for the loop construction, there is going an extra separator at the end\n",
    "        features_string = features_string[:-1]\n",
    "\n",
    "        csv_line = imageName + separator + label_name + separator + sublabel_name\n",
    "        csv_line = csv_line + separator + features_string\n",
    "        csv_line = csv_line + \"\\n\"\n",
    "        #print (csv_line)\n",
    "        f.write(csv_line)\n",
    "\n",
    "    #close the file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def features_csv_merge (input1_csv, input2_csv, output_csv, delimiter=','):\n",
    "    ids=[]\n",
    "    data = {}\n",
    "    with open(input1_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            ids.append(row[0])\n",
    "            data[row[0]] = [row[1], row[2], row[3:len(row)]]\n",
    "\n",
    "    with open(input2_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            [label, sublabel, f1] = data[row[0]]\n",
    "            data[row[0]] = [label, sublabel, f1, row[3:len(row)]]\n",
    "\n",
    "    f = open(output_csv, \"w\")\n",
    "    for id in ids:\n",
    "\n",
    "        label, sublabel, f1, f2 = data[id]\n",
    "\n",
    "        # Convert the features in a csv string\n",
    "        features_string = \"\"\n",
    "        for feature in f1:\n",
    "            features_string += feature + delimiter\n",
    "        for feature in f2:\n",
    "            features_string += feature + delimiter\n",
    "        # for the loop construction, there is going an extra delimiter at the end\n",
    "        features_string = features_string[:-1]\n",
    "\n",
    "        csv_line = id + delimiter + label + delimiter + sublabel\n",
    "        csv_line = csv_line + delimiter + features_string\n",
    "        csv_line = csv_line + \"\\n\"\n",
    "        #print (csv_line)\n",
    "        f.write(csv_line)\n",
    "\n",
    "    #close the file\n",
    "    f.close()\n",
    "\n",
    "\n",
    "def features_csv_to_tensor (input_csv, delimiter=','):\n",
    "    ids=[]\n",
    "    data=[]\n",
    "    with open(input_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            ids.append(row[0])\n",
    "            if (data == []):\n",
    "                data = [np.array(row)]\n",
    "            else:\n",
    "                data = np.append(c, [row], axis=0)\n",
    "\n",
    "\n",
    "def features_csv_to_features_data_container (input_csv, delimiter=',') -> DataContainer:\n",
    "    ids=[]\n",
    "    data=None\n",
    "    with open(input_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            ids.append(row[0])\n",
    "            if (data is None):\n",
    "                data = [np.array(row)]\n",
    "            else:\n",
    "                data = np.append(data, [row], axis=0)\n",
    "\n",
    "    x = np.asarray([torch.Tensor(x) for x in (np.delete(data, range(0, 3), 1)).astype(float)])\n",
    "    y = np.asarray([ToxoDataContainer.pathLabelsList.index(y) for y in data[:, 1]])\n",
    "\n",
    "    return DataContainer (x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KAmv6Y7stBpa"
   },
   "source": [
    "# Divisive normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.941951Z",
     "start_time": "2023-06-28T19:38:58.932909Z"
    },
    "id": "uHk--PIYtCOV"
   },
   "outputs": [],
   "source": [
    "# Original mask norm layer code extracted from https://gist.github.com/ilya16/c622461000480e66ae906dd9dbe8ea26\n",
    "# When using it as a layer in a CNN is not working yet because it's changing the number of channels of the filter\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.modules.instancenorm import _InstanceNorm\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class _DivisiveInstanceNorm(_InstanceNorm):\n",
    "    \n",
    "    def __init__(self, num_features, channels=64, kernel_size=3, eps=1e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True):\n",
    "        \n",
    "        super(_DivisiveInstanceNorm, self).__init__(num_features, eps, momentum, affine, track_running_stats)\n",
    "        \n",
    "        self.kernel_size=kernel_size\n",
    "        self.channels=channels\n",
    "        \n",
    "        # Define the convolution operation\n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=channels, \n",
    "                    kernel_size=self.kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "        self.conv.requires_grad_(False)\n",
    "        \n",
    "        \n",
    "    def makeGaussian(self, size, fwhm = 3, center=None):\n",
    "        \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "        size is the length of a side of the square\n",
    "        fwhm is full-width-half-maximum, which\n",
    "        can be thought of as an effective radius.\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.arange(0, size, 1, float)\n",
    "        y = x[:,np.newaxis]\n",
    "\n",
    "        if center is None:\n",
    "            x0 = y0 = size // 2\n",
    "        else:\n",
    "            x0 = center[0]\n",
    "            y0 = center[1]\n",
    "\n",
    "        return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "    \n",
    "    # Divisive Instance Normalization\n",
    "    def execute_divisive_instance_norm(self, input: Tensor) -> Tensor:\n",
    "        r\"\"\"Applies Divisive Instance Normalization for each channel in each data sample in a batch.\n",
    "        See :class:`~DivisiveInstanceNorm1d`, :class:`~DivisiveInstanceNorm2d`, :class:`~DivisiveInstanceNorm3d` for details.\n",
    "        \"\"\"\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        # Define the filter\n",
    "        kernel_weights = makeGaussian(self.kernel_size)\n",
    "        kernel_weights[math.floor(self.kernel_size/2), math.floor(self.kernel_size/2)] = 0\n",
    "        #kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "        kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "        kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "        kernel = kernel.expand(batch_size, self.channels, self.kernel_size, self.kernel_size)\n",
    "        \n",
    "        \n",
    "        # Define the bias\n",
    "        bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "        # Set the filter for the convolution operation\n",
    "        self.conv.weight = nn.Parameter(kernel)\n",
    "        #conv.bias = nn.Parameter(bias)\n",
    "        \n",
    "        \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() and input.is_cuda else \"cpu\")\n",
    "        self.conv.to(device)\n",
    "        \n",
    "        # Apply the convolution operation\n",
    "        filter = self.conv(input)\n",
    "\n",
    "        # Execute the division\n",
    "        out = torch.div(input, 1 + filter)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self.execute_divisive_instance_norm(input)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm1d(torch.nn.InstanceNorm1d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 3D input\n",
    "    (a mini-batch of 1D inputs with additional channel dimension)..\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm1d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, L)`\n",
    "        - Mask: :math:`(N, 1, L)`\n",
    "        - Output: :math:`(N, C, L)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm1d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm2d(torch.nn.InstanceNorm2d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 4D input\n",
    "    (a mini-batch of 2D inputs with additional channel dimension).\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm2d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, H, W)`\n",
    "        - Mask: :math:`(N, 1, H, W)`\n",
    "        - Output: :math:`(N, C, H, W)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm2d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm3d(torch.nn.InstanceNorm3d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 5D input\n",
    "    (a mini-batch of 3D inputs with additional channel dimension).\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm3d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, D, H, W)`\n",
    "        - Mask: :math:`(N, 1, D, H, W)`\n",
    "        - Output: :math:`(N, C, D, H, W)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm3d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26ZOvIuOGW1G"
   },
   "source": [
    "# **Models**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdBRuHqhGa7I"
   },
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.949871Z",
     "start_time": "2023-06-28T19:38:58.944035Z"
    },
    "id": "adNYziAdGqvD"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "## VGG uses 224x224x3 images as imput by default\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "def get_VGG19_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.VGG19_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.vgg19(weights=weights)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the last layer\n",
    "    number_features = model.classifier[6].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([torch.nn.Linear(number_features, 1)])\n",
    "    model.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "    return model\n",
    "\n",
    "# The difference on this one is that the reseted classifier is the full classifier instead of the last layer of the original classifier\n",
    "# One test done and performed worse but faster\n",
    "def get_VGG19_model_fc_linear2 (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.VGG19_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.vgg19(weights=weights)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the classifier head\n",
    "    num_ftrs = model.classifier[0].in_features\n",
    "    model.classifier = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WVZqT4MY3LUT"
   },
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.957792Z",
     "start_time": "2023-06-28T19:38:58.951258Z"
    },
    "id": "VsTiJpr63L3x"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "## DenseNet uses 64x64x3 images as imput by default, but is a parameter and 224 gives better results in preliminar tests\n",
    "crop_size = 460\n",
    "input_shape = 64\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "def get_densenet121_model_fc_linear (freeze=True, pretrained=True, output_features=1, num_init_features: int = 64, bn_size: int = 4, drop_rate: float = 0):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.DenseNet121_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.densenet121(weights=weights, num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the classifier head\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_densenet161_model_fc_linear (freeze=True, pretrained=True, output_features=1, num_init_features: int = 64, bn_size: int = 4, drop_rate: float = 0):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.DenseNet161_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.densenet161(weights=weights, num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the classifier head\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_densenet169_model_fc_linear (freeze=True, pretrained=True, output_features=1, num_init_features: int = 64, bn_size: int = 4, drop_rate: float = 0):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.DenseNet169_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.densenet169(weights=weights, num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the classifier head\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_densenet201_model_fc_linear (freeze=True, pretrained=True, output_features=1, num_init_features: int = 64, bn_size: int = 4, drop_rate: float = 0):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.DenseNet201_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.densenet201(weights=weights, num_init_features=num_init_features, bn_size=bn_size, drop_rate=drop_rate)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the classifier head\n",
    "    num_ftrs = model.classifier.in_features\n",
    "    model.classifier = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aewG-G-5H8ke"
   },
   "source": [
    "## ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.963871Z",
     "start_time": "2023-06-28T19:38:58.959001Z"
    },
    "id": "DsvuNFnqjKzL"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "## ResNet uses 224x224x3 images as imput by default\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def get_ResNet18_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ResNet18_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.resnet18(weights=weights)\n",
    "\n",
    "    # freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "def get_ResNet50_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ResNet50_Weights.IMAGENET1K_V2\n",
    "\n",
    "    model = models.resnet50(weights=weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ResNet101_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ResNet101_Weights.IMAGENET1K_V2\n",
    "\n",
    "    model = models.resnet101(weights=weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_ResNet152_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ResNet152_Weights.IMAGENET1K_V2\n",
    "\n",
    "    model = models.resnet152(weights=weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkWjtAU-u4Iv"
   },
   "source": [
    "## ResNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.968103Z",
     "start_time": "2023-06-28T19:38:58.965278Z"
    },
    "id": "EGktJy6Uu4JB"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def get_ResNeXt_model_fc_linear (freeze = False):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ResNeXt101_64X4D_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.resnext101_64x4d(weights = weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, 1)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSSGGyuaIbMB"
   },
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.972979Z",
     "start_time": "2023-06-28T19:38:58.969204Z"
    },
    "id": "G_lmlPSDSDLo"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "crop_size = 460\n",
    "input_shape = 518\n",
    "#mean = [0.485, 0.456, 0.406]\n",
    "#std = [0.229, 0.224, 0.225]\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.Normalize(mean, std)\n",
    "    ])\n",
    "\n",
    "# VIT\n",
    "class VitNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.vit = models.vit_h_14(weights = models.ViT_H_14_Weights.IMAGENET1K_SWAG_E2E_V1)\n",
    "        vit_out_features = (list(self.vit.heads.children())[0]).out_features\n",
    "        self.fc = nn.Linear(vit_out_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #x=torch.flatten(x)\n",
    "        x=self.vit(x)\n",
    "        z=self.fc(x)\n",
    "        #y=nnF.sigmoid(z, dim=1)\n",
    "        return z\n",
    "\n",
    "def get_vit_h_14_model_fc_linear (freeze = False):\n",
    "\n",
    "    model = VitNet()\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, 1)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2SPnZ9cdJvSQ"
   },
   "source": [
    "## ConvNext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.977186Z",
     "start_time": "2023-06-28T19:38:58.974050Z"
    },
    "id": "bRAyR2yP96gs"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ConvNext\n",
    "def get_convnext_large_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.ConvNeXt_Large_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.convnext_large(weights = weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the last layer\n",
    "    number_features = model.classifier[2].in_features\n",
    "    features = list(model.classifier.children())[:-1] # Remove last layer\n",
    "    features.extend([torch.nn.Linear(number_features, 1)])\n",
    "    model.classifier = torch.nn.Sequential(*features)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_f4PGODIaADZ"
   },
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.981103Z",
     "start_time": "2023-06-28T19:38:58.978261Z"
    },
    "id": "IKsPW29IaAs6"
   },
   "outputs": [],
   "source": [
    "## Transformations, usually model-dependentant\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "def get_inception_v3_model_fc_linear (freeze=True, pretrained=True, output_features=1):\n",
    "\n",
    "    weights = None\n",
    "    if pretrained:\n",
    "        weights = models.Inception_V3_Weights.IMAGENET1K_V1\n",
    "\n",
    "    model = models.inception_v3(weights=weights)\n",
    "\n",
    "    ## freeze the layers\n",
    "    if freeze:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Modify the last layer\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = nn.Sequential (\n",
    "        nn.Linear(num_ftrs, output_features)\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yeZFsr8zaav"
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:38:58.985385Z",
     "start_time": "2023-06-28T19:38:58.981998Z"
    },
    "id": "MeCQCbK0zavW"
   },
   "outputs": [],
   "source": [
    "class MLP_one_hidden_layer(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super().__init__()\n",
    "        self.input_layer  = nn.Linear(input_features, hidden_features)\n",
    "        self.hidden_layer = nn.Linear(hidden_features, hidden_features)\n",
    "        self.output_layer = nn.Linear(hidden_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.input_layer(x)\n",
    "        x=self.hidden_layer(x)\n",
    "        z=self.output_layer(x)\n",
    "        return z\n",
    "\n",
    "class MLP_two_hidden_layer(nn.Module):\n",
    "    def __init__(self, input_features, hidden_features, output_features):\n",
    "        super().__init__()\n",
    "        self.input_layer  = nn.Linear(input_features, hidden_features)\n",
    "        self.hidden1_layer = nn.Linear(hidden_features, hidden_features)\n",
    "        self.hidden2_layer = nn.Linear(hidden_features, hidden_features)\n",
    "        self.output_layer = nn.Linear(hidden_features, output_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=self.input_layer(x)\n",
    "        x=self.hidden1_layer(x)\n",
    "        x=self.hidden2_layer(x)\n",
    "        z=self.output_layer(x)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XS93Bu_9sJe"
   },
   "source": [
    "# **Examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xj1H70z4TKeg"
   },
   "source": [
    "## Data manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p2kQ3OwSyB0Y"
   },
   "source": [
    "### Load data & check consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YAhNQnawyCq5"
   },
   "outputs": [],
   "source": [
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "print(\"Data shape: \", dataContainer.data.shape)\n",
    "print(\"Train shape: \", (dataContainer.get_full_train()[1]).shape)\n",
    "print(\"Train, FV, Test intersection void: \", dataContainer.check_intersection())\n",
    "print(\"Check folds intersection: \", dataContainer.check_folds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tAHNjFRQzcZJ"
   },
   "source": [
    "### Saving and loading a partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bM4N4XWczbSj"
   },
   "outputs": [],
   "source": [
    "# Note that the dataset must be loaded normally, the partition load only overrides the split done\n",
    "# while loading the dataset\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "savePath = \"./example.txt\"\n",
    "dataContainer.save_partition(savePath)\n",
    "dataContainer.load_partition(savePath)\n",
    "dataContainer.final_val_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ffZZMLJ1TTmE"
   },
   "source": [
    "### Saving transformed images examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhboMM8aTYa8"
   },
   "outputs": [],
   "source": [
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "dataContainer.save_transformed_images(indexes=[5, 10, 15, 25], base_name=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WqRd8rtgenuA"
   },
   "source": [
    "### Saving transformed dataset (TODO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TDn67cOjeoRF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3Lo3fZr8Q_q"
   },
   "source": [
    "## Training and prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gvi52oE85tUH"
   },
   "source": [
    "### Multiclass classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BRbb4iN95uRM"
   },
   "outputs": [],
   "source": [
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "test_dataloader = dataContainer.get_test_dataloader()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = MulticlassClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=2)\n",
    "\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_generator(model))\n",
    "trainingController.print_metrics_short(val_metrics, '\\n\\n\\tValidation metrics of the returned model:')\n",
    "\n",
    "# In case you need the full epoch evolution metrics\n",
    "#returned_model, returned_epoch, epoch_tracking_list = self.train_model_(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_generator(model))\n",
    "#(train_metrics, val_metrics) = epoch_tracking_list[returned_epoch]\n",
    "#trainingController.print_metrics_short(val_metrics, '\\n\\n\\tValidation metrics of the returned model:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vT-Ua0i5ut-"
   },
   "source": [
    "### Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fwqQmBib5u_O"
   },
   "outputs": [],
   "source": [
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "test_dataloader = dataContainer.get_test_dataloader()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=1)\n",
    "\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_generator(model))\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tValidation metrics of the returned model:')\n",
    "\n",
    "# In case you need the full epoch evolution metrics\n",
    "#returned_model, returned_epoch, epoch_tracking_list = self.train_model_(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_generator(model))\n",
    "#(train_metrics, val_metrics) = epoch_tracking_list[returned_epoch]\n",
    "#trainingController.print_metrics_long(val_metrics, '\\n\\n\\tValidation metrics of the returned model:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ6EQJu9yRHp"
   },
   "source": [
    "### Multiclass classification CF-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ky69Ra6jTdtL",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "trainingController = MulticlassClassificationTrainingController (criterion=criterion, max_epochs=num_epochs, verbose=False)\n",
    "\n",
    "# Number fo features = 2 for it to be multiclass\n",
    "def model_generator(): return get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=2)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YE4iAym4yWR7"
   },
   "source": [
    "### Binary classification CF-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:15:05.691432Z",
     "start_time": "2023-06-28T20:11:44.877676Z"
    },
    "id": "7i-dlYk4TfiR"
   },
   "outputs": [],
   "source": [
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6gWJxdP4yqAi"
   },
   "source": [
    "### Manual CF-Validation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJxrp_Am7inS"
   },
   "outputs": [],
   "source": [
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "trained_models = []\n",
    "result = []\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "trainingController = MulticlassClassificationTrainingController (criterion=criterion, max_epochs=num_epochs, verbose=False)\n",
    "\n",
    "since = time.time()\n",
    "for fold in range(0, dataContainer.k_splits):\n",
    "    print('\\n--------------------------------------------------------------\\n')\n",
    "    print('fold:', fold, '\\n------------')\n",
    "    train_dataloader, val_dataloader = dataContainer.get_fold_dataloaders(fold, batch_size=32)\n",
    "\n",
    "    model = get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=2)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    returned_model, returned_epoch, epoch_tracking_list = trainingController.train_model_(\n",
    "                    model, train_dataloader, val_dataloader,\n",
    "                    optimizer=optimizer, plot_evolution=False)\n",
    "    trained_models.append(returned_model)\n",
    "    (train_metrics, val_metrics) = epoch_tracking_list[returned_epoch]\n",
    "    result.append(val_metrics)\n",
    "\n",
    "print('\\n--------------------------------------------------------------\\n')\n",
    "time_elapsed = time.time() - since\n",
    "print('Full CV in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "\n",
    "\n",
    "print('\\nAverage metrics:', trainingController.average_metrics (result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aG1LHIpP2i_E"
   },
   "source": [
    "### Full experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_S1ff4k2nVy"
   },
   "outputs": [],
   "source": [
    "# CF-Validation is used to have an stable reading of the perfomance of a model in order to\n",
    "# be able to compare different hyperparameters optimization of one architecture.\n",
    "# Once the hyperparameters have been selected, we make a training loop with al the training\n",
    "# data and evaluate in the test subset, which has never been seen before by the model.\n",
    "# In this example, we compare the fine tunning versus the frozen of the transfered\n",
    "# part Oof transfer learning in ResNet18\n",
    "\n",
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "# Training environment preparation. 2 variations of the same model to be compared\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator1(): return get_ResNet18_model_fc_linear(freeze=False, pretrained=True, output_features=1)\n",
    "def model_generator2(): return get_ResNet18_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Execute cf-validation over each model variation\n",
    "average_results1 = trainingController.execute_cross_fold(dataContainer, model_generator1, optimizer_generator)\n",
    "average_results2 = trainingController.execute_cross_fold(dataContainer, model_generator2, optimizer_generator)\n",
    "\n",
    "# Decide the best model (looking at f1 score for instance)\n",
    "trainingController.print_metrics_long(average_results1, '\\n\\n\\tModel 1:')\n",
    "trainingController.print_metrics_long(average_results2, '\\n\\n\\tModel 2:')\n",
    "\n",
    "# Compare F1-Score to select the best model\n",
    "best_model_generator = model_generator1 if average_results1[\"f1\"] >= average_results2[\"f1\"] else model_generator2\n",
    "\n",
    "# Use the subsets of full train to train, final validation to check convergence and test to obtain the final results for that model\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "test_dataloader = dataContainer.get_test_dataloader()\n",
    "\n",
    "# Execute one training loop for the best model\n",
    "final_model = best_model_generator()\n",
    "optimizer_final_model = optimizer_generator(final_model)\n",
    "final_model, val_metrics = trainingController.train_model(final_model, full_train_dataloader, final_val_dataloader, optimizer=optimizer_final_model)\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(final_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xmYIj0tT92CC"
   },
   "source": [
    "### Extract output of a layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geRuZjmq909h"
   },
   "outputs": [],
   "source": [
    "# https://kozodoi.me/python/deep%20learning/pytorch/tutorial/2021/05/27/extracting-features.html\n",
    "\n",
    "# Define a variable and an observer function (hook) that, each time the model is\n",
    "# executed to predict, will put the value of the selected layer in the variable\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "antsAndBeesDataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "# Model\n",
    "model = get_ResNet18_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "\n",
    "# Add hook to the selected layer\n",
    "model.layer4.register_forward_hook(get_activation('layer4'))\n",
    "model.avgpool.register_forward_hook(get_activation('avgpool'))\n",
    "model.fc.register_forward_hook(get_activation('fc'))\n",
    "\n",
    "# Get Input\n",
    "test_dataloader = antsAndBeesDataContainer.get_test_dataloader(batch_size=1)\n",
    "dataIterator = iter(test_dataloader)\n",
    "(img,label)=next(dataIterator)\n",
    "\n",
    "# Obtain full mopdel output\n",
    "output = model(img)\n",
    "\n",
    "# Retrieve, from the variable defined at the begining, the output that the hook has saved\n",
    "#print(activation['avgpool'])\n",
    "torch.flatten(activation['avgpool']).cpu().numpy().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwXxMBBI8N83"
   },
   "source": [
    "### Transform images to model features  (before classifier head) and save to csv fille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-lHI3ijoTl33"
   },
   "outputs": [],
   "source": [
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "# Features file destination\n",
    "fileName = \"example_ants_and_bees_features_ResNet18_512+2.csv\"\n",
    "\n",
    "# Model\n",
    "model = get_VGG19_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "model.eval()\n",
    "\n",
    "# Add hook (activation) to the selected layer. It needs to be a dictionary because pointers obscure wizardy\n",
    "observers = {}\n",
    "observer_name='features'\n",
    "model.classifier[3].register_forward_hook(get_activation(observers, observer_name))\n",
    "\n",
    "# Call the function\n",
    "transform_images_to_features_csv (model, observers, observer_name, dataContainer, output_file=fileName, sublabels=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRxTwR3Ytfwd"
   },
   "source": [
    "## Divisive normalization exercicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8vJSVP6thK3"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "\n",
    "kernel_size = 5\n",
    "channels = 3\n",
    "\n",
    "# Define the filter\n",
    "kernel_weights = makeGaussian(kernel_size)\n",
    "kernel_weights[math.floor(kernel_size/2), math.floor(kernel_size/2)] = 0\n",
    "#kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "print(kernel, '\\n')\n",
    "kernel = kernel.expand(1, channels, kernel_size, kernel_size)\n",
    "\n",
    "# Define the bias\n",
    "bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "#print(img.shape, '\\n')\n",
    "\n",
    "# Define the convolution operation\n",
    "conv = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "conv.requires_grad_(False)\n",
    "\n",
    "# Set the filter for the convolution operation\n",
    "conv.weight = nn.Parameter(kernel)\n",
    "conv.bias = nn.Parameter(bias)\n",
    "\n",
    "\n",
    "# Apply the convolution operation\n",
    "output = conv(img)\n",
    "\n",
    "#print(output, '\\n')\n",
    "\n",
    "result = torch.div(img, 1+output)\n",
    "result_img = transforms.ToPILImage()(result.detach().squeeze(0))\n",
    "\n",
    "#print(result, '\\n')\n",
    "\n",
    "pictures = 10\n",
    "\n",
    "plot_size=3\n",
    "vseparation = 0.25\n",
    "figures= 3\n",
    "fig, ax = plt.subplots(pictures, 4, figsize=(plot_size*4, (plot_size + 0.25) * pictures))\n",
    "fig.subplots_adjust(hspace=vseparation)\n",
    "for i in range(0,pictures):\n",
    "\n",
    "    (img,label)=next(dataIterator)\n",
    "\n",
    "    output = conv(img)\n",
    "\n",
    "    result = torch.div(img, 1+output)\n",
    "    result_img = transforms.ToPILImage()(result.detach().squeeze(0))\n",
    "\n",
    "    ax[i, 0].imshow((np.asarray(img.squeeze(0))).transpose((1, 2, 0)))\n",
    "    ax[i, 0].set_title('Input', fontsize=16)\n",
    "    ax[i, 1].imshow((output.detach().squeeze(0).numpy()).transpose((1, 2, 0)))\n",
    "    ax[i, 1].set_title('Divisor', fontsize=16)\n",
    "    ax[i, 2].imshow(result_img)\n",
    "    ax[i, 2].set_title('Output', fontsize=16)\n",
    "    ax[i, 3].imshow(torchvision.transforms.functional.equalize(result_img))\n",
    "    ax[i, 3].set_title('Output equalized', fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_XAyhNXqRsGa"
   },
   "source": [
    "## XAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhNyGrVsRrAY"
   },
   "outputs": [],
   "source": [
    "modelList=[]\n",
    "\n",
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "                 transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "breakHisDataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "\n",
    "# Training environment preparation. 2 variations of the same model to be compared\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "# Use the subsets of full train, final validation and test to obtain the final results for that model\n",
    "full_train_dataloader = breakHisDataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = breakHisDataContainer.get_final_val_dataloader()\n",
    "test_dataloader = breakHisDataContainer.get_test_dataloader()\n",
    "\n",
    "# Model 1\n",
    "model_pre = get_ResNet18_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "optimizer_pre = optim.Adam(model_pre.parameters(), lr=0.001)\n",
    "\n",
    "_, pretrained_ResNet18_metrics, pretrained_ResNet18_model = trainingController.train_model(model_pre, full_train_dataloader, final_val_dataloader, optimizer=optimizer_pre)\n",
    "modelList.append((\"Resnet18_pretrained\", pretrained_ResNet18_model))\n",
    "\n",
    "# Model 2\n",
    "model_not_pre = get_ResNet18_model_fc_linear(freeze=True, pretrained=False, output_features=1)\n",
    "optimizer_not_pre = optim.Adam(model_not_pre.parameters(), lr=0.001)\n",
    "\n",
    "_, not_pretrained_ResNet18_metrics, not_ResNet18_model = trainingController.train_model(model_not_pre, full_train_dataloader, final_val_dataloader, optimizer=optimizer_not_pre)\n",
    "modelList.append((\"Resnet18_not_pretrained\", not_ResNet18_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rmIGUiUpRusu"
   },
   "outputs": [],
   "source": [
    "cam_test_dataloader = breakHisDataContainer.get_test_dataloader(batch_size=1)\n",
    "cam_dataIterator = iter(cam_test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9R5JbKkiRupv"
   },
   "outputs": [],
   "source": [
    "(img,label)=next(cam_dataIterator)\n",
    "\n",
    "#explaination_multiple_models (img, label, modelList)\n",
    "cam_multiple_models (img, label, modelList, 'gradcam', label_list_str=breakHisDataContainer.pathLabelsList)\n",
    "cam_multiple_models (img, label, modelList, 'eigencam', label_list_str=breakHisDataContainer.pathLabelsList)\n",
    "cam_multiple_models (img, label, modelList, 'fullgrad', label_list_str=breakHisDataContainer.pathLabelsList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vAcqIEznV7mn"
   },
   "source": [
    "# **Experimentations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wz7LbA07t3CY"
   },
   "source": [
    "## Divisive normalization experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:41:37.283457Z",
     "start_time": "2023-06-28T19:41:30.382102Z"
    },
    "id": "BnPSDR8XuN5M"
   },
   "outputs": [],
   "source": [
    "# Experiment to see the effect of the filter on a few images\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "kernel_size = 5\n",
    "channels = 3\n",
    "\n",
    "# Define the filter\n",
    "kernel_weights = makeGaussian(kernel_size)\n",
    "kernel_weights[math.floor(kernel_size/2), math.floor(kernel_size/2)] = 0\n",
    "#kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "print(kernel, '\\n')\n",
    "kernel = kernel.expand(1, channels, kernel_size, kernel_size)\n",
    "\n",
    "# Define the bias\n",
    "bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "#print(img.shape, '\\n')\n",
    "\n",
    "# Define the convolution operation\n",
    "conv = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "conv.requires_grad_(False)\n",
    "print (conv)\n",
    "\n",
    "# Set the filter for the convolution operation\n",
    "conv.weight = nn.Parameter(kernel)\n",
    "#conv.bias = nn.Parameter(bias)\n",
    "\n",
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize(input_shape),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = AntsAndBeesDataContainer(antsAndBeesFolderPath, transformations=data_transforms)\n",
    "test_dataloader = dataContainer.get_data_dataloader(batch_size=1)\n",
    "dataIterator = iter(test_dataloader)\n",
    "\n",
    "(img,label)=next(dataIterator)\n",
    "\n",
    "#print(result, '\\n')\n",
    "\n",
    "plot_size=3\n",
    "vseparation = 0.25\n",
    "figures= 3\n",
    "fig, ax = plt.subplots(10, 4, figsize=(plot_size*4, (plot_size + 0.25) * 10))\n",
    "fig.subplots_adjust(hspace=vseparation)\n",
    "for i in range(0,10):\n",
    "\n",
    "    (img,label)=next(dataIterator)\n",
    "\n",
    "    output = conv(img)\n",
    "\n",
    "    result = torch.div(img, 1+output)\n",
    "    result_img = transforms.ToPILImage()(result.detach().squeeze(0))\n",
    "\n",
    "    ax[i, 0].imshow((np.asarray(img.squeeze(0))).transpose((1, 2, 0)))\n",
    "    ax[i, 0].set_title('Input', fontsize=16)\n",
    "    ax[i, 1].imshow((output.detach().squeeze(0).numpy()).transpose((1, 2, 0)))\n",
    "    ax[i, 1].set_title('Divisor', fontsize=16)\n",
    "    ax[i, 2].imshow(result_img)\n",
    "    ax[i, 2].set_title('Output', fontsize=16)\n",
    "    ax[i, 3].imshow(torchvision.transforms.functional.equalize(result_img))\n",
    "    ax[i, 3].set_title('Output equalized', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:44:44.076010Z",
     "start_time": "2023-06-28T19:44:44.020762Z"
    },
    "id": "pZGQWnHGt3Cq"
   },
   "outputs": [],
   "source": [
    "# Experiment about applying the filter to the full dataset as a preprocessing\n",
    "\n",
    "kernel_size = 5\n",
    "channels = 3\n",
    "\n",
    "# Define the filter\n",
    "kernel_weights = makeGaussian(kernel_size)\n",
    "kernel_weights[math.floor(kernel_size/2), math.floor(kernel_size/2)] = 0\n",
    "#kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "print(kernel, '\\n')\n",
    "kernel = kernel.expand(1, channels, kernel_size, kernel_size)\n",
    "\n",
    "# Define the bias\n",
    "bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "#print(img.shape, '\\n')\n",
    "\n",
    "# Define the convolution operation\n",
    "conv = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "conv.requires_grad_(False)\n",
    "\n",
    "# Set the filter for the convolution operation\n",
    "conv.weight = nn.Parameter(kernel)\n",
    "conv.bias = nn.Parameter(bias)\n",
    "\n",
    "for i in range(0, dataContainer.data.shape[0]):\n",
    "    #dataContainer.data[i] = (torch.div(torch.tensor(dataContainer.data[i]), 1 + conv(torch.tensor(dataContainer.data[i])))).detach().numpy()\n",
    "    result_img = torch.div(torch.tensor(dataContainer.data[i]), 1 + conv(torch.tensor(dataContainer.data[i])))\n",
    "    result_img = transforms.ToPILImage()(result_img.detach().squeeze(0))\n",
    "    dataContainer.data[i] = torch.tensor(torchvision.transforms.functional.equalize(result_img))\n",
    "\n",
    "# Training environment preparation. 2 variations of the same model to be compared\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return get_ResNet18_model_fc_linear(freeze=True, pretarined=True, output_features=1)\n",
    "\n",
    "def model_generator_divisive(freeze=True, pretarined=True, output_features=1):\n",
    "    model = model_generator()\n",
    "    model.bn1 = DivisiveInstanceNorm2d (64 * 224 * 224, 5)\n",
    "    return model\n",
    "\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "\n",
    "# Use the subsets of full train, final validation and test to obtain the final results for that model\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "test_dataloader = dataContainer.get_test_dataloader()\n",
    "\n",
    "# Train the model and evaluate\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "trained_model, epoch, epoch_traking_list = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer)\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(trained_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:04:58.814244Z",
     "start_time": "2023-06-28T20:04:58.787911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Original mask norm layer code extracted from https://gist.github.com/ilya16/c622461000480e66ae906dd9dbe8ea26\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.modules.instancenorm import _InstanceNorm\n",
    "\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "class _DivisiveInstanceNorm(_InstanceNorm):\n",
    "    \n",
    "    def __init__(self, num_features, channels=64, kernel_size=3, eps=1e-5, momentum=0.1, affine=True,\n",
    "                 track_running_stats=True):\n",
    "        \n",
    "        super(_DivisiveInstanceNorm, self).__init__(num_features, eps, momentum, affine, track_running_stats)\n",
    "        \n",
    "        self.kernel_size=kernel_size\n",
    "        self.channels=channels\n",
    "        \n",
    "        # Define the convolution operation\n",
    "        self.conv = nn.Conv2d(in_channels=channels, out_channels=channels, \n",
    "                    kernel_size=self.kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "        self.conv.requires_grad_(False)\n",
    "        \n",
    "        \n",
    "    def makeGaussian(self, size, fwhm = 3, center=None):\n",
    "        \"\"\" Make a square gaussian kernel.\n",
    "\n",
    "        size is the length of a side of the square\n",
    "        fwhm is full-width-half-maximum, which\n",
    "        can be thought of as an effective radius.\n",
    "        \"\"\"\n",
    "\n",
    "        x = np.arange(0, size, 1, float)\n",
    "        y = x[:,np.newaxis]\n",
    "\n",
    "        if center is None:\n",
    "            x0 = y0 = size // 2\n",
    "        else:\n",
    "            x0 = center[0]\n",
    "            y0 = center[1]\n",
    "\n",
    "        return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "    \n",
    "    # Divisive Instance Normalization\n",
    "    def execute_divisive_instance_norm(self, input: Tensor) -> Tensor:\n",
    "        r\"\"\"Applies Divisive Instance Normalization for each channel in each data sample in a batch.\n",
    "        See :class:`~DivisiveInstanceNorm1d`, :class:`~DivisiveInstanceNorm2d`, :class:`~DivisiveInstanceNorm3d` for details.\n",
    "        \"\"\"\n",
    "        batch_size = input.shape[0]\n",
    "\n",
    "        # Define the filter\n",
    "        kernel_weights = makeGaussian(self.kernel_size)\n",
    "        kernel_weights[math.floor(self.kernel_size/2), math.floor(self.kernel_size/2)] = 0\n",
    "        #kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "        kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "        kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "        kernel = kernel.expand(batch_size, self.channels, self.kernel_size, self.kernel_size)\n",
    "        \n",
    "        \n",
    "        # Define the bias\n",
    "        bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "        # Set the filter for the convolution operation\n",
    "        self.conv.weight = nn.Parameter(kernel)\n",
    "        #conv.bias = nn.Parameter(bias)\n",
    "        \n",
    "        \n",
    "        device = torch.device(\"cuda:0\" if torch.cuda.is_available() and input.is_cuda else \"cpu\")\n",
    "        self.conv.to(device)\n",
    "        \n",
    "        # Apply the convolution operation\n",
    "        filter = self.conv(input)\n",
    "        \n",
    "        print(\"conv: \", self.conv)\n",
    "        print(\"input.shape: \", input.shape)\n",
    "        print(\"Kernel.shape: \", kernel.shape)\n",
    "        print(\"filter.shape: \", filter.shape)\n",
    "\n",
    "        # Execute the division\n",
    "        out = torch.div(input, 1 + filter)\n",
    "\n",
    "        return out\n",
    "\n",
    "    \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self.execute_divisive_instance_norm(input)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm1d(torch.nn.InstanceNorm1d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 3D input\n",
    "    (a mini-batch of 1D inputs with additional channel dimension)..\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm1d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, L)`\n",
    "        - Mask: :math:`(N, 1, L)`\n",
    "        - Output: :math:`(N, C, L)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm1d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm2d(torch.nn.InstanceNorm2d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 4D input\n",
    "    (a mini-batch of 2D inputs with additional channel dimension).\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm2d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, H, W)`\n",
    "        - Mask: :math:`(N, 1, H, W)`\n",
    "        - Output: :math:`(N, C, H, W)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm2d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)\n",
    "\n",
    "\n",
    "class DivisiveInstanceNorm3d(torch.nn.InstanceNorm3d, _DivisiveInstanceNorm):\n",
    "    r\"\"\"Applies Divisive Normalization over a 5D input\n",
    "    (a mini-batch of 3D inputs with additional channel dimension).\n",
    "    See documentation of :class:`~torch.nn.InstanceNorm3d` for details.\n",
    "    Shape:\n",
    "        - Input: :math:`(N, C, D, H, W)`\n",
    "        - Mask: :math:`(N, 1, D, H, W)`\n",
    "        - Output: :math:`(N, C, D, H, W)` (same shape as input)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_features: int, channels=64, kernel_size=3, eps: float = 1e-5, momentum: float = 0.1,\n",
    "                 affine: bool = False, track_running_stats: bool = False) -> None:\n",
    "        super(DivisiveInstanceNorm3d, self).__init__(\n",
    "            num_features, channels, kernel_size, eps, momentum, affine, track_running_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T20:04:59.725100Z",
     "start_time": "2023-06-28T20:04:59.208464Z"
    },
    "id": "cl00IXbTt_q_"
   },
   "outputs": [],
   "source": [
    "# Experiment changing the normalization layer of a CNN\n",
    "\n",
    "####################\n",
    "\n",
    "# Use the subsets of full train, final validation and test to obtain the final results for that model\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "test_dataloader = dataContainer.get_test_dataloader()\n",
    "\n",
    "# Training environment preparation.\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return get_ResNet18_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "# Create a model\n",
    "model = model_generator()\n",
    "\n",
    "# Change the first normalization for our divisive instance normalization\n",
    "model.bn1 = DivisiveInstanceNorm2d (64 * 224 * 224, 64, 5)\n",
    "\n",
    "# Training\n",
    "optimizer = optimizer_generator(model)\n",
    "trained_model, epoch, epoch_traking_list = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer)\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(final_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-28T19:53:19.593367Z",
     "start_time": "2023-06-28T19:53:19.593338Z"
    },
    "id": "tyeR8E0tvL8u"
   },
   "outputs": [],
   "source": [
    "# Execute one training loop with the normal architecture for comparison pruporses\n",
    "#final_model = best_model()\n",
    "normal_model = model_generator()\n",
    "optimizer = optimizer_generator(normal_model)\n",
    "trained_normal_model, epoch, epoch_traking_list = trainingController.train_model(normal_model, full_train_dataloader, final_val_dataloader, optimizer=optimizer)\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(trained_normal_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest normal model:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm4Zojmrt35V"
   },
   "source": [
    "## Feature extraction experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZB5EKh5-t1Sp"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "\n",
    "kernel_size = 5\n",
    "channels = 3\n",
    "\n",
    "# Define the filter\n",
    "kernel_weights = makeGaussian(kernel_size)\n",
    "kernel_weights[math.floor(kernel_size/2), math.floor(kernel_size/2)] = 0\n",
    "#kernel_weights = kernel_weights / sum(kernel_weights)\n",
    "\n",
    "kernel = torch.tensor(kernel_weights, dtype=torch.float32)\n",
    "kernel = kernel.reshape(1, 1, kernel_size, kernel_size)\n",
    "print(kernel, '\\n')\n",
    "kernel = kernel.expand(1, channels, kernel_size, kernel_size)\n",
    "\n",
    "# Define the bias\n",
    "bias = torch.tensor([0], dtype=torch.float32)\n",
    "\n",
    "#print(img.shape, '\\n')\n",
    "\n",
    "# Define the convolution operation\n",
    "conv = nn.Conv2d(in_channels=channels, out_channels=channels, kernel_size=kernel_size, bias=False, padding=math.floor(kernel_size/2))\n",
    "conv.requires_grad_(False)\n",
    "\n",
    "# Set the filter for the convolution operation\n",
    "conv.weight = nn.Parameter(kernel)\n",
    "conv.bias = nn.Parameter(bias)\n",
    "\n",
    "\n",
    "# Apply the convolution operation\n",
    "output = conv(img)\n",
    "\n",
    "#print(output, '\\n')\n",
    "\n",
    "result = torch.div(img, 1+output)\n",
    "result_img = transforms.ToPILImage()(result.detach().squeeze(0))\n",
    "\n",
    "#print(result, '\\n')\n",
    "\n",
    "pictures = 10\n",
    "\n",
    "plot_size=3\n",
    "vseparation = 0.25\n",
    "figures= 3\n",
    "fig, ax = plt.subplots(pictures, 4, figsize=(plot_size*4, (plot_size + 0.25) * pictures))\n",
    "fig.subplots_adjust(hspace=vseparation)\n",
    "for i in range(0,pictures):\n",
    "\n",
    "    (img,label)=next(dataIterator)\n",
    "\n",
    "    output = conv(img)\n",
    "\n",
    "    result = torch.div(img, 1+output)\n",
    "    result_img = transforms.ToPILImage()(result.detach().squeeze(0))\n",
    "\n",
    "    ax[i, 0].imshow((np.asarray(img.squeeze(0))).transpose((1, 2, 0)))\n",
    "    ax[i, 0].set_title('Input', fontsize=16)\n",
    "    ax[i, 1].imshow((output.detach().squeeze(0).numpy()).transpose((1, 2, 0)))\n",
    "    ax[i, 1].set_title('Divisor', fontsize=16)\n",
    "    ax[i, 2].imshow(result_img)\n",
    "    ax[i, 2].set_title('Output', fontsize=16)\n",
    "    ax[i, 3].imshow(torchvision.transforms.functional.equalize(result_img))\n",
    "    ax[i, 3].set_title('Output equalized', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FFRXM70YfwoJ"
   },
   "outputs": [],
   "source": [
    "# Dataset reading\n",
    "crop_size = 460\n",
    "input_shape = 224\n",
    "data_transforms =  transforms.Compose([\n",
    "        #transforms.CenterCrop(crop_size),\n",
    "        transforms.Resize((input_shape, input_shape)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "dataContainer = ToxoDataContainer(toxoFolderPath, transformations=data_transforms, lazy=False)\n",
    "print(dataContainer.check_intersection())\n",
    "print(dataContainer.check_folds())\n",
    "x, y = dataContainer.get_data()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gf6fMRJhBAdY"
   },
   "outputs": [],
   "source": [
    "fileNameVgg = \"1000images_VGG19_4096_features_+2.csv\"\n",
    "#fileName = \"VGG19.csv\"\n",
    "# Model\n",
    "model = get_VGG19_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "model.eval()\n",
    "\n",
    "# Add hook (activation) to the selected layer. It needs to be a dictionary because pointers obscure wizardy\n",
    "observers = {}\n",
    "observer_name='features'\n",
    "model.classifier[3].register_forward_hook(get_activation(observers, observer_name))\n",
    "\n",
    "# Call the function\n",
    "transform_images_to_features_csv (model, observers, observer_name, dataContainer, output_file=fileNameVgg, sublabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjXqqrR7fx6o"
   },
   "outputs": [],
   "source": [
    "fileNameResNet = \"1000images_ResNet18_512_features_+2.csv\"\n",
    "#fileName = \"ResNet18.csv\"\n",
    "\n",
    "# Model\n",
    "model = get_ResNet18_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "model.eval()\n",
    "\n",
    "# Add hook (activation) to the selected layer. It needs to be a dictionary because pointers obscure wizardy\n",
    "observers = {}\n",
    "observer_name='features'\n",
    "model.avgpool.register_forward_hook(get_activation(observers, observer_name))\n",
    "\n",
    "# Call the function\n",
    "transform_images_to_features_csv (model, observers, observer_name, dataContainer, output_file=fileName, sublabels=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rNZjTU7jkU17"
   },
   "outputs": [],
   "source": [
    "fileNameInception = \"1000images_Inception_V3_2048_features_+2.csv\"\n",
    "\n",
    "# Model\n",
    "model = get_inception_v3_model_fc_linear(freeze=True, pretrained=True, output_features=1)\n",
    "model.eval()\n",
    "\n",
    "# Add hook (activation) to the selected layer. It needs to be a dictionary because pointers obscure wizardy\n",
    "observers = {}\n",
    "observer_name='features'\n",
    "model.avgpool.register_forward_hook(get_activation(observers, observer_name))\n",
    "\n",
    "# Call the function\n",
    "transform_images_to_features_csv (model, observers, observer_name, dataContainer, output_file=fileNameInception, sublabels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1FOCNA5gvVGn"
   },
   "outputs": [],
   "source": [
    "fileNameVgg = \"1000images_VGG19_4096_features_+2.csv\"\n",
    "fileNameResNet = \"1000images_ResNet18_512_features_+2.csv\"\n",
    "fileNameInception = \"1000images_Inception_V3_2048_features_+2.csv\"\n",
    "\n",
    "fileNameVggResNet = \"1000images_VGG19+ResNet18_4608_features_+2.csv\"\n",
    "#features_csv_merge(fileNameVgg, fileNameResNet, fileNameVggResNet)\n",
    "\n",
    "fileNameVggInception = \"1000images_VGG19+Inception_V3_4144_features_+2.csv\"\n",
    "#features_csv_merge(fileNameVgg, fileNameInception, fileNameVggInception)\n",
    "\n",
    "fileNameResNetInception = \"1000images_ResNet18+Inception_V3_2560_features_+2.csv\"\n",
    "#features_csv_merge(fileNameResNet, fileNameInception, fileNameResNetInception)\n",
    "\n",
    "fileNameVGGResNetInception = \"1000images_VGG19+ResNet18+Inception_V3_7168_features_+2.csv\"\n",
    "#features_csv_merge(fileNameVggResNet, fileNameResNetInception, fileNameVGGResNetInception)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cBIu8C5wIL5o"
   },
   "source": [
    "## Extrated Features datasets prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "edbXpFTV8Fzc"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameResNet)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AaEuQyhD5kIT"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameResNet)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yS-cYcLeLY3g"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrltiPyOFUoJ"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVgg)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sFJIHhUxFUb5"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVgg)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfgTp2ZiLXss"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Antn-3XP75qx"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-QU8pcAKrse"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8vCl5NsCLWoz"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEwCdZdoK335"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVggResNet)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm6eYfkBK3wQ"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVggResNet)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j1JCgJ11K3c1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lm-IWavwK3YW"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVggInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TZVGtE-9K1Yq"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameVggInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qdmTIZaK1O1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vq1QjmlfLRhb"
   },
   "outputs": [],
   "source": [
    "dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameResNetInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqs7sIWxLRZH"
   },
   "outputs": [],
   "source": [
    "#dataContainer = features_csv_to_features_data_container(toxoFolderPath + \"/\" + fileNameResNetInception)\n",
    "x, y = dataContainer.get_data()\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)\n",
    "\n",
    "model = MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "\n",
    "#average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, save_plot_filename=\"resnet18_features_MLP_1h_CF\")\n",
    "average_results = trainingController.execute_cross_fold(dataContainer, model_generator, optimizer_generator, stop_on_convergence=False)\n",
    "trainingController.print_metrics_long(average_results, '\\n\\n\\tExample long metrics print:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AUtWwFk0IRw3"
   },
   "source": [
    "## Toxo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "error",
     "timestamp": 1687198411925,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "YElC_xXUIWK7",
    "outputId": "18b2c2fb-8ecd-4513-e9f6-1da47f1e5f56"
   },
   "outputs": [],
   "source": [
    "def features_csv_to_features_data_container_toxo (input_csv, delimiter=',') -> DataContainer:\n",
    "    ids=[]\n",
    "    data=None\n",
    "    with open(input_csv) as csv_file:\n",
    "        csv_reader = csv.reader(csv_file, delimiter=delimiter)\n",
    "        line_count = 0\n",
    "        for row in csv_reader:\n",
    "            ids.append(row[0])\n",
    "            if (data is None):\n",
    "                data = [np.array(row)]\n",
    "            else:\n",
    "                data = np.append(data, [row], axis=0)\n",
    "\n",
    "    x = np.asarray([torch.Tensor(x) for x in (data[:, 3:]).astype(float)])\n",
    "    y = np.asarray([ToxoDataContainer.pathLabelsList.index(y) for y in data[:, 1]])\n",
    "    z = np.asarray([z == \"30. Toxo\" for z in data[:, 2]])\n",
    "\n",
    "    #return DataContainer (x, y)\n",
    "    return (x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "aborted",
     "timestamp": 1687198411927,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "m_2YjBa9WUSZ"
   },
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "trainingController = BinaryClassificationTrainingController (criterion=criterion, max_epochs=100, verbose=False)\n",
    "\n",
    "def model_generator(): return MLP_one_hidden_layer(x[0].shape[0], x[0].shape[0], 1)\n",
    "def optimizer_generator(model): return optim.Adam(model.parameters(), lr=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1687198411928,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "sAm7JWZTTcos"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameVgg)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "aborted",
     "timestamp": 1687198411929,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "L4v_PZMUIftm"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameResNet)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "aborted",
     "timestamp": 1687198411930,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "0FQlUQx6XjzV"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameInception)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "aborted",
     "timestamp": 1687198411931,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "lU94YaqeXjxF"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameVggResNet)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "aborted",
     "timestamp": 1687198411933,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "1ZGhhd0TXjur"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameVggInception)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "aborted",
     "timestamp": 1687198411934,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "vp70ZF4FXjr0"
   },
   "outputs": [],
   "source": [
    "# Read data. X are the features, y the labels, and z if it's toxo or not\n",
    "x, y, z = features_csv_to_features_data_container_toxo(toxoFolderPath + \"/\" + fileNameResNetInception)\n",
    "\n",
    "# Remove toxo from data\n",
    "x2, y2 = x[np.logical_not(z)], y[np.logical_not(z)]\n",
    "xz, yz = x[z], y[z]\n",
    "\n",
    "# Create data container without toxo. Test and final val size at 20% due to small healthy examples\n",
    "dataContainer = DataContainer (x2, y2, test_size=0.2, final_val_size=0.2)\n",
    "\n",
    "# Obtain the \"Healthy\" class from the test set\n",
    "d, t = dataContainer.get_test()\n",
    "dn, tn = d[t==1], t[t==1]\n",
    "\n",
    "# Concat test healthy examples with toxo examples, create dataset and dataloader with it\n",
    "data, targets = np.append(dn, xz, axis=0), np.append(tn, yz, axis=0)\n",
    "test_dataset = MyDataset(data, targets)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=1)\n",
    "\n",
    "# Obtain training and validation dataloaders that do not contain toxo\n",
    "full_train_dataloader = dataContainer.get_full_train_dataloader()\n",
    "final_val_dataloader = dataContainer.get_final_val_dataloader()\n",
    "\n",
    "# Model creation\n",
    "model = model_generator()\n",
    "optimizer = optimizer_generator(model)\n",
    "\n",
    "# Train model without toxo data\n",
    "returned_model, val_metrics = trainingController.train_model(model, full_train_dataloader, final_val_dataloader, optimizer=optimizer, stop_on_convergence=True)\n",
    "trainingController.print_metrics_long(val_metrics, '\\n\\n\\tExample long metrics print:')\n",
    "\n",
    "# Evaluate over the test data\n",
    "test_metrics = trainingController.get_evaluation_metrics(returned_model, test_dataloader)\n",
    "trainingController.print_metrics_long(test_metrics, '\\n\\n\\tTest:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "aborted",
     "timestamp": 1687198411935,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "Br_kxuBhXjpP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 25,
     "status": "aborted",
     "timestamp": 1687198411936,
     "user": {
      "displayName": "Nicolas Catalan",
      "userId": "07457230843770320156"
     },
     "user_tz": -120
    },
    "id": "sk5HaM6mXjl5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "xEqv64xtGNxu",
    "bUgPuvGp-_WI",
    "zcCD5QYU_MrK",
    "26ZOvIuOGW1G",
    "sdBRuHqhGa7I",
    "WVZqT4MY3LUT",
    "aewG-G-5H8ke",
    "xkWjtAU-u4Iv",
    "nSSGGyuaIbMB",
    "2SPnZ9cdJvSQ",
    "_f4PGODIaADZ",
    "6yeZFsr8zaav",
    "p2kQ3OwSyB0Y",
    "tAHNjFRQzcZJ",
    "ffZZMLJ1TTmE",
    "WqRd8rtgenuA",
    "Gvi52oE85tUH",
    "_vT-Ua0i5ut-",
    "aZ6EQJu9yRHp",
    "YE4iAym4yWR7",
    "6gWJxdP4yqAi",
    "aG1LHIpP2i_E",
    "xmYIj0tT92CC",
    "_XAyhNXqRsGa",
    "Wz7LbA07t3CY",
    "Qm4Zojmrt35V",
    "cBIu8C5wIL5o",
    "AUtWwFk0IRw3"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "211.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
